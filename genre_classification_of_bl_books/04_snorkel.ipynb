{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51cI_Ac_g35C"
   },
   "source": [
    "# Creating More Training Data Without More Annotating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0OfUwq_g35E"
   },
   "source": [
    "We previously listed 'annotating' more data as one way of improving our model. Since supervised learning requires data, having more data *may* be *potentially* helpful for improving our model. \n",
    "\n",
    "One obvious downside of this is that collecting more training data is time consuming and may not always be very practical. In a GLAM setting we may want to use machine learning to do a task which we wouldn't otherwise have time to do. If we have to spend a lot of time creating our training data, the machine learning approach may also become impractical in terms of resources. \n",
    "\n",
    "## Combining Domain Expertise and Machine Learning \n",
    "\n",
    "The time taken to create training data is one weakness of machine learning for practical tasks. Another potential frustration domain experts may have is that their knowledge isn't always incorporated into the machine learning process. For our use case of trying to identify the genre of a book we may already have a sense of some possible ways in which we could identify whether a book was fiction or non-fiction. For example we may already know that titles for non-fiction books tend to be longer than fiction book titles (cf. 'An account of the mining villages of Wales' vs 'Oliver Twist'). If we create our training data in the usual way by labeling examples of our data with the correct label we might not be able to incorporate this domain knowledge very easily. This might be okay in some cases but we might be able to save time and get better results by trying to leverage what we already know (or can access via domain experts). \n",
    "\n",
    "## Programmatically Generating Training Data \n",
    "\n",
    "One way in which we could do this is by writing a `labelling function` to label titles as being either fiction or non-fiction based on the length of the title - i.e. without any annotation by hand. However, a weakness of this approach is that it deals with averages which might not always be correct. Some non-fiction book titles will be shorter than our threshold, and vice-versa for fiction books. If we could simply determine genre based on the average length of titles, we could have skipped this whole machine learning process and be done already. \n",
    "\n",
    "So our problem is that we have some sense of functions we could use to label our data, but these functions are likely to be wrong some of the time. In this notebook we'll explore how we can use a Python library `Snorkel` to deal with this challenge and try and create additional annotations without doing any annotating by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcT3lm7OrAox"
   },
   "source": [
    "### Generating New Genre Training Data\n",
    "\n",
    "How will we try to approach this in our particular situation? As a reminder of our broad task, we have a collection of metadata related to the Microsoft Digitised Books collection. The 'genre' field isn't yet fully populated. We have previously used a subset of this data to train a machine learning model. \n",
    "\n",
    "What we want to do is to try and write some labelling functions that will add more labels to the full metadata dataset, so that we can give our models more examples to learn from. If we are able to do this we'll hopefully be able to improve the performance of our model from our previous attempts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhsycB7WrAoy"
   },
   "source": [
    "We'll start by doing some installation of our libraries we'll be using in this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UEXy4fu-vhn",
    "outputId": "93f039f4-e4a5-4ce2-e4bf-802c5e4e5cff",
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snorkel in /usr/local/lib/python3.7/dist-packages (0.9.7)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.9.0+cu111)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.4.1)\n",
      "Requirement already satisfied: munkres>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.4)\n",
      "Requirement already satisfied: numpy<1.20.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.19.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.62.3)\n",
      "Requirement already satisfied: scikit-learn<0.25.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (0.22.2.post1)\n",
      "Requirement already satisfied: networkx<2.4,>=2.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.3)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.5)\n",
      "Requirement already satisfied: tensorboard<2.0.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<2.4,>=2.2->snorkel) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.0.0->snorkel) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.20.2->snorkel) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (1.41.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (57.4.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.17.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.0.0,>=1.14.0->snorkel) (3.3.4)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (4.8.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0.0,>=1.2.0->snorkel) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.0.0,>=1.14.0->snorkel) (3.6.0)\n",
      "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.5.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.2)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu111)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.27)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
      "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
      "Requirement already satisfied: torch<1.11,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu111)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
      "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress>=0.2.4->fastai) (1.19.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.62.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.10.0.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install snorkel\n",
    "!pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c0sn-qng35G"
   },
   "source": [
    "Since we already have some training data we can leverage this to help us develop `labelling functions` (more on this below) and to test how well these work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqthas8M9xGI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO_hAG8ZukzD"
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"BL record ID\": \"string\",\n",
    "    \"Type of resource\": \"category\",\n",
    "    \"Name\": \"category\",\n",
    "    \"Type of name\": \"category\",\n",
    "    \"Country of publication\": \"category\",\n",
    "    \"Place of publication\": \"category\",\n",
    "    \"Genre\": \"category\",\n",
    "    \"Dewey classification\": \"string\",\n",
    "    \"BL record ID for physical resource\": \"string\",\n",
    "    \"annotator_main_language\": \"category\",\n",
    "    \"annotator_summaries_language\": \"string\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdhYVzND-11V"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Living-with-machines/genre-classification/main/genre_classification_of_bl_books/data/train_valid.csv\", dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "_mfAhwnz_Dfj",
    "outputId": "6276c5e4-f4e6-453c-c340-a00142397edb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BL record ID</th>\n",
       "      <th>Type of resource</th>\n",
       "      <th>Name</th>\n",
       "      <th>Dates associated with name</th>\n",
       "      <th>Type of name</th>\n",
       "      <th>Role</th>\n",
       "      <th>All names</th>\n",
       "      <th>Title</th>\n",
       "      <th>Variant titles</th>\n",
       "      <th>Series title</th>\n",
       "      <th>Number within series</th>\n",
       "      <th>Country of publication</th>\n",
       "      <th>Place of publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Date of publication</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Physical description</th>\n",
       "      <th>Dewey classification</th>\n",
       "      <th>BL shelfmark</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Notes</th>\n",
       "      <th>BL record ID for physical resource</th>\n",
       "      <th>classification_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>subject_ids</th>\n",
       "      <th>annotator_date_pub</th>\n",
       "      <th>annotator_normalised_date_pub</th>\n",
       "      <th>annotator_edition_statement</th>\n",
       "      <th>annotator_genre</th>\n",
       "      <th>annotator_FAST_genre_terms</th>\n",
       "      <th>annotator_FAST_subject_terms</th>\n",
       "      <th>annotator_comments</th>\n",
       "      <th>annotator_main_language</th>\n",
       "      <th>annotator_other_languages_summaries</th>\n",
       "      <th>annotator_summaries_language</th>\n",
       "      <th>annotator_translation</th>\n",
       "      <th>annotator_original_language</th>\n",
       "      <th>annotator_publisher</th>\n",
       "      <th>annotator_place_pub</th>\n",
       "      <th>annotator_country</th>\n",
       "      <th>annotator_title</th>\n",
       "      <th>Link to digitised book</th>\n",
       "      <th>annotated</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014616539</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hazlitt, William Carew, 1834-1913 [person]</td>\n",
       "      <td>The Baron's Daughter. A ballad by the author o...</td>\n",
       "      <td>Single Works</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Ballantyne, Hanson</td>\n",
       "      <td>1877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 pages (4°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 11651.h.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000206670</td>\n",
       "      <td>263940444.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-07-27 07:35:13 UTC</td>\n",
       "      <td>44330917.0</td>\n",
       "      <td>1877</td>\n",
       "      <td>1877</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ballantyne Hanson &amp; Co.</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>stk</td>\n",
       "      <td>The Baron's Daughter. A ballad by the author o...</td>\n",
       "      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BL record ID Type of resource  ... annotated is_valid\n",
       "0    014616539        Monograph  ...      True    False\n",
       "\n",
       "[1 rows x 47 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ho5uND7rAo2"
   },
   "source": [
    "We'll use only the data from the training split so we're can continue to use the validation split to compare our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOCO7jwmXm5q"
   },
   "outputs": [],
   "source": [
    "df = df[df.is_valid == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13K97iYtrAo2"
   },
   "source": [
    "Check how many examples we have to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N46XPfQ6rAo3",
    "outputId": "b9a90fdd-cb83-4df3-c9d3-df5d89ae370f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3262"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zl-UzJGJXvSb"
   },
   "source": [
    "## What is a labeling function?\n",
    "\n",
    "We briefly described a function we could use to label our data using the length of the title. When we use a programmatic approach to creating our training data we can refer to the functions which we use to create our labels as `labeling function`. We'll follow a lot of the approaches outlined in the Snorkel [tutorial](https://www.snorkel.org/use-cases/01-spam-tutorial) in this notebook. They provide this example of a labeling function for the task of identifying if a youtube comment is spam or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vc9PPFVF-1Ne"
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf_contains_link(x):\n",
    "    # Return a label of SPAM if \"http\" in comment text, otherwise ABSTAIN\n",
    "    return SPAM if \"http\" in x.text.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR9bds16rAo4"
   },
   "source": [
    "There are a few things to note here, but, since we're following a lot of what is covered in the Snorkel tutorial we won't repeat things in too much detail. \n",
    "\n",
    "The first thing we need is to import `labeling_function` from `snorkel` as we use this for declaring our labeling functions. The way in which we create a labeling function will depend on our data, and how we might label it, but in this example we have a simple python function which returns `SPAM` if the text `http` appears in the comment text, if it doesn't it returns `ABSTAIN`. \n",
    "\n",
    "We use a python decorator to indicate that this is a labeling function. If you aren't familiar with Python decorators should just remember that decorators are used to modify the behavior of a function (the one it decorates), just as fairy lights decorate a Christmas tree  and change its behaviour from 'tree' to 'festive ornament'. This will make more sense in the context of Snorkel later on. \n",
    "\n",
    "If you want to dig into decorators further this [article](https://realpython.com/primer-on-python-decorators/) on [Real Python](https://realpython.com/) provides a nice introduction, or, if prefer to watch a video this [youtube tutorial](https://youtu.be/FsAPt_9Bf3U) gives a nice overview too. \n",
    "\n",
    "We can see here that the labeling function makes use of the idea that people often include links in spam comments i.e. \"plz checkout my etsy store at http:....\". Obviously this won't be correct all the time but fortunately Snorkel has some ways to deal with this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8phqjBAfg35K"
   },
   "source": [
    "## What Makes a Good Labelling Function?\n",
    "\n",
    "One question we might already have is \"what makes a good labeling function?\". The short, annoying, answer is that it depends on context. We often have intutions about things that might work because we know the domain or have picked up ideas from working with some of the data already. In our particular example of distinguishing fiction from non-fiction books we may think that some words are likely to indicate whether a book is fiction or non-fiction. We'll start by exploring this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADZDmy-ZXj9L"
   },
   "source": [
    "### Important Words?\n",
    "\n",
    "A fairly naive approach to trying to labeling a title as 'fiction' or 'non-fiction' would be to use some keywords. Let's start by finding the most common 50 words. We can use the `Counter` class from the delightful [`collections`](https://docs.python.org/3.3/library/collections.html#module-collections) module to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_v_WkSmc_GpP"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Td7nUd_U_MmO",
    "outputId": "ce9e67b8-eb15-415d-eee3-944f23129494",
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 2255),\n",
       " ('the', 1785),\n",
       " ('and', 1536),\n",
       " ('...', 1054),\n",
       " ('in', 819),\n",
       " ('The', 693),\n",
       " ('A', 625),\n",
       " ('a', 625),\n",
       " ('etc', 557),\n",
       " ('by', 472),\n",
       " ('to', 413),\n",
       " ('With', 314),\n",
       " ('from', 268),\n",
       " ('with', 250),\n",
       " ('de', 228),\n",
       " ('van', 223),\n",
       " ('By', 201),\n",
       " ('its', 196),\n",
       " ('en', 194),\n",
       " ('der', 193),\n",
       " ('History', 179),\n",
       " ('J.', 159),\n",
       " ('on', 158),\n",
       " ('an', 157),\n",
       " ('[With', 157),\n",
       " ('[A', 152),\n",
       " ('illustrations', 152),\n",
       " ('New', 125),\n",
       " ('other', 121),\n",
       " ('for', 117),\n",
       " ('novel.]', 111),\n",
       " ('edition', 110),\n",
       " ('or,', 109),\n",
       " ('H.', 108),\n",
       " ('Illustrated', 98),\n",
       " ('A.', 96),\n",
       " ('und', 91),\n",
       " ('af', 88),\n",
       " ('G.', 87),\n",
       " ('den', 87),\n",
       " ('och', 75),\n",
       " ('C.', 73),\n",
       " ('or', 72),\n",
       " ('i', 71),\n",
       " ('het', 70),\n",
       " ('An', 68),\n",
       " ('Edited', 67),\n",
       " ('novel', 67),\n",
       " ('W.', 64),\n",
       " ('during', 64)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df[\"Title\"]).split()).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Eg5-qGprAo6"
   },
   "source": [
    "We can see here that the most common words tend to be [stop words](https://en.wikipedia.org/wiki/Stop_word). Since we want to know which words might be unique to fiction *or* non-fiction we'll look at each of these separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GomIMxJx_0Bo"
   },
   "outputs": [],
   "source": [
    "df_fiction = df[df[\"annotator_genre\"] == \"Fiction\"]\n",
    "df_non_fiction = df[df[\"annotator_genre\"] == \"Non-fiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWtrBzGS_yB9",
    "outputId": "aba45afd-285f-4c8b-afd5-7db8c2df62c6",
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 490),\n",
       " ('The', 331),\n",
       " ('A', 316),\n",
       " ('the', 260),\n",
       " ('and', 242),\n",
       " ('a', 184),\n",
       " ('...', 177),\n",
       " ('[A', 147),\n",
       " ('by', 138),\n",
       " ('in', 112),\n",
       " ('novel.]', 111),\n",
       " ('etc', 104),\n",
       " ('By', 104),\n",
       " ('other', 94),\n",
       " ('novel', 67),\n",
       " ('With', 53),\n",
       " ('tale', 50),\n",
       " ('der', 49),\n",
       " ('edition', 48),\n",
       " ('de', 47),\n",
       " ('author', 45),\n",
       " ('van', 45),\n",
       " ('or,', 41),\n",
       " ('en', 40),\n",
       " ('Poems', 39),\n",
       " ('J.', 39),\n",
       " ('story', 39),\n",
       " ('illustrations', 38),\n",
       " ('[i.e.', 35),\n",
       " ('A.', 34),\n",
       " ('stories', 30),\n",
       " ('romance', 29),\n",
       " ('H.', 28),\n",
       " ('poems', 28),\n",
       " ('or', 26),\n",
       " ('Second', 26),\n",
       " ('und', 26),\n",
       " ('C.', 25),\n",
       " ('poem', 25),\n",
       " ('with', 25),\n",
       " ('verse', 24),\n",
       " ('An', 24),\n",
       " ('from', 24),\n",
       " ('Tales', 24),\n",
       " ('New', 23),\n",
       " ('for', 20),\n",
       " ('acts', 20),\n",
       " ('collection', 20),\n",
       " ('het', 20),\n",
       " ('an', 19)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_fiction = Counter(\" \".join(df_fiction[\"Title\"]).split()).most_common(50)\n",
    "most_frequent_fiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7rOUj2R_7Kg",
    "outputId": "3008eb6e-84df-46fa-8c0e-ea968cff4025",
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 1765),\n",
       " ('the', 1525),\n",
       " ('and', 1294),\n",
       " ('...', 877),\n",
       " ('in', 707),\n",
       " ('etc', 453),\n",
       " ('a', 441),\n",
       " ('to', 397),\n",
       " ('The', 362),\n",
       " ('by', 334),\n",
       " ('A', 309),\n",
       " ('With', 261),\n",
       " ('from', 244),\n",
       " ('with', 225),\n",
       " ('its', 193),\n",
       " ('de', 181),\n",
       " ('van', 178),\n",
       " ('History', 176),\n",
       " ('en', 154),\n",
       " ('on', 153),\n",
       " ('[With', 144),\n",
       " ('der', 144),\n",
       " ('an', 138),\n",
       " ('J.', 120),\n",
       " ('illustrations', 114),\n",
       " ('New', 102),\n",
       " ('for', 97),\n",
       " ('By', 97),\n",
       " ('Illustrated', 94),\n",
       " ('af', 88),\n",
       " ('H.', 80),\n",
       " ('och', 75),\n",
       " ('den', 75),\n",
       " ('G.', 74),\n",
       " ('i', 71),\n",
       " ('or,', 68),\n",
       " ('und', 65),\n",
       " ('during', 64),\n",
       " ('edition', 62),\n",
       " ('A.', 62),\n",
       " ('history', 62),\n",
       " ('og', 61),\n",
       " ('account', 57),\n",
       " ('sketches', 54),\n",
       " ('W.', 53),\n",
       " ('P.', 51),\n",
       " ('through', 51),\n",
       " ('notes', 50),\n",
       " ('edition,', 50),\n",
       " ('het', 50)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_non_fiction = Counter(\n",
    "    \" \".join(df_non_fiction[\"Title\"]).split()\n",
    ").most_common(50)\n",
    "most_frequent_non_fiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJmfefqirAo6"
   },
   "source": [
    "For our indicator words to be most reliable we would rather they didn't appear frequently in both fiction and non-fiction titles. We can use a set to check the values which aren't in both fiction and non-fiction titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arePlnW4ATST",
    "outputId": "0657eb32-1513-4418-9321-48e28daaba70",
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('...', 877),\n",
       " ('A', 309),\n",
       " ('A.', 62),\n",
       " ('By', 97),\n",
       " ('G.', 74),\n",
       " ('H.', 80),\n",
       " ('History', 176),\n",
       " ('Illustrated', 94),\n",
       " ('J.', 120),\n",
       " ('New', 102),\n",
       " ('P.', 51),\n",
       " ('The', 362),\n",
       " ('W.', 53),\n",
       " ('With', 261),\n",
       " ('[With', 144),\n",
       " ('a', 441),\n",
       " ('account', 57),\n",
       " ('af', 88),\n",
       " ('an', 138),\n",
       " ('and', 1294),\n",
       " ('by', 334),\n",
       " ('de', 181),\n",
       " ('den', 75),\n",
       " ('der', 144),\n",
       " ('during', 64),\n",
       " ('edition', 62),\n",
       " ('edition,', 50),\n",
       " ('en', 154),\n",
       " ('etc', 453),\n",
       " ('for', 97),\n",
       " ('from', 244),\n",
       " ('het', 50),\n",
       " ('history', 62),\n",
       " ('i', 71),\n",
       " ('illustrations', 114),\n",
       " ('in', 707),\n",
       " ('its', 193),\n",
       " ('notes', 50),\n",
       " ('och', 75),\n",
       " ('of', 1765),\n",
       " ('og', 61),\n",
       " ('on', 153),\n",
       " ('or,', 68),\n",
       " ('sketches', 54),\n",
       " ('the', 1525),\n",
       " ('through', 51),\n",
       " ('to', 397),\n",
       " ('und', 65),\n",
       " ('van', 178),\n",
       " ('with', 225)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(most_frequent_non_fiction).difference(set(most_frequent_fiction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eD2gmHF3rAo7"
   },
   "source": [
    "These words are still fairly noisy so we might be wary of using many of them. There are some which make sense intuitively so we'll try some of these out and see how they perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPs0v2kdrAo7"
   },
   "source": [
    "## Creating our Labelling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHCYPdUvOYvQ"
   },
   "source": [
    "We'll start by setting some constants for our labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L59RHzHFBRCg"
   },
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "FICTION = 0\n",
    "NON_FICTION = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-oDd7N-g35O"
   },
   "source": [
    "It is important to note that we set an option for `ABSTAIN`. We often want to add an option to our labeling functions that defers from making a prediction. We usually write our labeling function to try and indicate a label, but usually if the function isn't satisfied doesn't indicate that the other label is correct. \n",
    "\n",
    "Another important part of labeling functions is that we usually want to have many labeling functions, and, since we're not relying on a single function to label our data it's often better for our labeling function to return `ABSTAIN` if our labeling condition isn't met rather than returning another label. This becomes even more important if we have multiple labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13OCfSJkrAo8"
   },
   "source": [
    "One function we could try to start with is checking if the word \"Novel\" appears in the title text. You may have noticed that in this particular dataset the word novel often appears as part of the title so this *could* be a useful indicator of fiction titles. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7_zwuo1rAo8"
   },
   "source": [
    "```{warning}\n",
    "We want to be careful that our labeling functions are specific to our data. In the BL books title metadata that we're trying to label we have noticed that things like `A Novel by...` appear in the title. This may not be the case for other book titles in different catalogues.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C5k-NMvrAo9"
   },
   "source": [
    "Our first labeling function is basically the same as the spam example above except we look for the word \"novel\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGQJd9t9BHXj"
   },
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_contains_novel(x):\n",
    "    return FICTION if \"novel\" in x.Title.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwnGvjV6rAo9"
   },
   "source": [
    "Now we have our labeling function we can apply it to our data. We'll start by doing this only with our validation data since we have the correct labels for this to compare our functions against. \n",
    "\n",
    "There are various ways in which Snorkel can apply our functions to our data. In this notebook we'll stick with an approach designed to work with Pandas dataframes. If we have a larger amount of data to label we might want to explore the use of [dask applifer functions](https://snorkel.readthedocs.io/en/v0.9.6/packages/_autosummary/labeling/snorkel.labeling.apply.dask.DaskLFApplier.html). This uses the [dask](https://dask.org/) library to scale the appliation of labelling functions to very large datasets. We won't need this here but if you are planning to develop this approach with very large collections this could be worth exploring. \n",
    "\n",
    "We put our labelling functions in a list called `LFS`, we then create an applier object and pass in our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arlsWXgdCQN9",
    "outputId": "c5e9d49d-76e3-4603-9847-7a15949df082"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3262/3262 [00:00<00:00, 39484.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [lf_contains_novel]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnxmW_t3rAo9"
   },
   "source": [
    "We store the output of this in a new variable `L_train`. We can use `LFAnalysis` to get a summary of what our current labeling function is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "GqVyZOT-CV1e",
    "outputId": "b10e5361-11e5-4491-caed-5adc8ca1f464"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_contains_novel</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.058553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_contains_novel  0      [0]  0.058553       0.0        0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3DA6cGcrAo-"
   },
   "source": [
    "We can see a row for our current labeling function, we can also see that at the moment our coverage (i.e. how much of our data is labeled by our function) is very low. At the moment we don't have any overlaps or conflicts since these are relevant only when we have multiple labeling functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA8JJ2mjOhJn"
   },
   "source": [
    "We have ground truth labels that we can use to evaluate how accurate our labeling function is. To to his we need to use the same labels as Snorkel for ground truth so we'll map our labels to the constants we made above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7anTHbVEwud"
   },
   "outputs": [],
   "source": [
    "ground_truth = df.annotator_genre.replace({\"Fiction\": 0, \"Non-fiction\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEk6ynRarAo_"
   },
   "source": [
    "We can pass our ground truth labels to `lf_empirical_accuracies` to get a sumaary of the peformance of our functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2Hajt1aCafV",
    "outputId": "922196c5-f6f7-4b78-95e3-55e40273757b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_empirical_accuracies(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUH7BP8rrAo_"
   },
   "source": [
    "We can see here that our current function is 100% accurate. We shouldn't get too excited about this since our coverage is very low. We'll need to write some more labeling functions to make sure that we have some chance of labeling more of our data than we currently have done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU5Es8RQOk1v"
   },
   "source": [
    "## Heuristics\n",
    "\n",
    "We could also use heuristics for our labeling functions. For example the length of the title. I don't have any idea what threshold to use for this. Since we have some labels we can try and identify a sensible threshold. First we'll add a new columns to our DataFrame which contains the length of our titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foZMdb3eFuan"
   },
   "outputs": [],
   "source": [
    "df[\"text_len\"] = df[\"Title\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJYR9TiEJBYp"
   },
   "source": [
    "We'll now use a pandas `groupby` to see what the lengths look like for fiction vs non-fiction books. Since it might be useful to have a sense of the distributions we'll use `describe` instead of mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "adfVLYdEFq-j",
    "outputId": "4592ffb8-a36a-4cad-caa8-78fe7a2d8302"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annotator_genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fiction</th>\n",
       "      <td>1083.0</td>\n",
       "      <td>49.438596</td>\n",
       "      <td>35.095600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-fiction</th>\n",
       "      <td>2179.0</td>\n",
       "      <td>92.317118</td>\n",
       "      <td>58.458339</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>469.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count       mean        std  min   25%   50%    75%    max\n",
       "annotator_genre                                                             \n",
       "Fiction          1083.0  49.438596  35.095600  5.0  25.0  39.0   63.0  271.0\n",
       "Non-fiction      2179.0  92.317118  58.458339  8.0  50.0  78.0  125.0  469.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"annotator_genre\"])[\"text_len\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XaH65IprApA"
   },
   "source": [
    "### Precision vs Recall: What Value to use for our Threshold?\n",
    "\n",
    "We can see various values for mean, min etc. What would be a reasonable value to use for our threshold for a labeling function which labeled a title as 'non-fiction'? This partly comes down to whether we want high coverage (or recall) or high precision. If we choose a threshold that is higher we will label fewer examples, but they will be more likely to be correct. \n",
    "\n",
    "For example, if we use the max value for the length of a non-fiction title `469` most titles will be much shorter than this, so our function will 'abstain' from applying a label, and we would only label a very small number of examples from our data. However, we also won't have many (or any) wrongly-labeled examples since the max value for fiction here is `288`. We need to balance these two aims of coverage and precision. Since we are writing more than one labeling function we probably want to tend towards writing more precise labeling functions rather than aiming for high coverage if this is likely to introduce wrongly labeled examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjF-CazwrApA"
   },
   "source": [
    "```{note}\n",
    "As we saw in previous chapters/notebooks we have to be a bit careful in generalizing between what we see in our training and validation data since there may be some distribution drift between our training data (which wasn't a completely randomized sample) and the full data that we want to label. In the error analysis notebook we saw that the performance of our model was worse than it was on validation data. We should keep this in mind when writing a labeling function, since we want our labeling function to work well on new data which doesn't have labels, not just on the data for which we already have labels. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUvJHmQDrApB"
   },
   "source": [
    "We'll use the value of the maximum title length for a fiction book as our threshold. This will *hopefully* give us fairly decent coverage without too many mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjE-Ynm-G9FN"
   },
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_is_long_title(x):\n",
    "    return NON_FICTION if x.text_len > 211.0 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1ejaFH6rApB"
   },
   "source": [
    "We do the same as earlier, including our new labeling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "un6NNGppHb-g",
    "outputId": "8afece44-64db-4fdf-d074-8d5357f29b3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3262/3262 [00:00<00:00, 28729.01it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [lf_contains_novel, lf_is_long_title]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "J1p1N3EOHjJp",
    "outputId": "248b4999-673b-42fc-8914-8930eae7b36a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_contains_novel</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.058553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_is_long_title</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_contains_novel  0      [0]  0.058553       0.0        0.0\n",
       "lf_is_long_title   1      [1]  0.023299       0.0        0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBIeuc8DrApC"
   },
   "source": [
    "We can see our coverage is still fairly low but at the moment we don't have any conflicts. We can keep tweaking our length threshold but for now we'll try a different approach to our labeling function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz5zMWyIPBTV"
   },
   "source": [
    "### Add Keywords\n",
    "\n",
    "We already have a labeling function that uses the keyword 'novel' to identify likely fiction books. Since we often want to use keywords the Snorkel tutorial suggests a way we can do this more easily using [keyword lookups](https://www.snorkel.org/use-cases/01-spam-tutorial#a-keyword-lfs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opfuiriNHk4Y"
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelingFunction\n",
    "\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.Title.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=FICTION):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUJlky69rApC"
   },
   "source": [
    "We can try two new keyword labels using this more concise approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfQBSDyRILUZ"
   },
   "outputs": [],
   "source": [
    "keyword_tale = make_keyword_lf(keywords=[\"tale\"])\n",
    "keyword_poem = make_keyword_lf(keywords=[\"poem\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjxWantoI4I6"
   },
   "source": [
    "## Leveraging Other Models\n",
    "\n",
    "So far we have leveraged some domain knowledge/exploration and our existing labeled data to create our labeling functions. However, we could also utilise other resources to help us label our data. Since we're working with text we should be able to benefit from some existing NLP models to label our data. Snorkel supports this in a few different ways. \n",
    "\n",
    "spaCy is a popular nlp library which supports a range of different models and nlp tasks. Here we're particuarly interested in some of the named entity models supported by spaCy. \n",
    "\n",
    "To work with this library we can use Snorkel's `SpacyPreProcessor`. `Preprocessors` are used in Snorkel to do some preprocessing (hence the name) which is required for our labeling functions. These can be particularly useful if the processing takes some time and might be reused across differnet labelling functions. Let's take a look at an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFXy3VK7IrfG"
   },
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "# The SpacyPreprocessor parses the text in text_field and\n",
    "# stores the new enriched representation in doc_field\n",
    "spacy = SpacyPreprocessor(text_field=\"Title\", doc_field=\"doc\", memoize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7SRDdwKrApD"
   },
   "source": [
    "Above we create a `SpacyPreprocessor` which will use our title field and create a new `doc` field. This `doc` refers to the Spacy [`doc`](https://spacy.io/api/doc) container. This can be reused for multiple different labeling functions. We pass in `memoize=True` to cache our results. This means we won't have to wait for the preprocessing to be done multiple times for different labeling functions which reuse the `doc` container. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ea4D5OsrApD"
   },
   "source": [
    "### Using named entities for labeling functions. \n",
    "\n",
    "spaCy has support for named entity recognition. Since these models are already created and can be used directly by us it might be worth seeing if named entities are of any benefit for our particular task. \n",
    "\n",
    "We can again draw from our domain knowledge, intution or guesses (depending on how confident we are) and say that it's likely that we will see more named entities of the `ORG` type in non-fiction titles since these often will be about organizations. We can combine this with a slightly softer threshold for length to label titles as being likely non-fiction. \n",
    "\n",
    "To create this function we replicate closely what we did before except that we pass in our `SpacyPreProcessor` instance to let Snorkel know that this preprocesser is a requirement of this labeling function. Under the hood this will mean that if the preprocessor hasn't been run already this will triger the preprocessing. If we reuse this for another funciton the preprocessing will already have been cached. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iq44hdK_J8yb"
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def has_many_org(x):\n",
    "    if len(x.doc) > 50 and len([ent.label_ == \"ORG\" for ent in x.doc.ents]) > 1:\n",
    "        return NON_FICTION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC3ubh8drApD"
   },
   "source": [
    "We might also guess that there will be more location entities in non-fiction titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TNrqJdRKMMd"
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def has_many_loc(x):\n",
    "    if len(x.doc) > 50 and len([ent.label_ == \"LOC\" for ent in x.doc.ents]) > 2:\n",
    "        return NON_FICTION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ79M4JVrApD"
   },
   "source": [
    "Similarly we might also assume that there will be more `GPE` entities for non-fiction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDMstH6ALFN5"
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def has_many_gpe(x):\n",
    "    if len(x.doc) > 50 and len([ent.label_ == \"GPE\" for ent in x.doc.ents]) > 2:\n",
    "        return NON_FICTION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEnw_cQIrApE"
   },
   "source": [
    "and law entities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTrXPjseSleA"
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def has_law(x):\n",
    "    if any([ent.label_ == \"LAW\" for ent in x.doc.ents]):\n",
    "        return NON_FICTION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb3sfKp1rApE"
   },
   "source": [
    "and if it's long and has a date it might be a non-fiction title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNK-T-oUUYtY"
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def is_long_and_has_date(x):\n",
    "    if len(x.doc) > 50 and any([ent.label_ == \"DATE\" for ent in x.doc.ents]):\n",
    "        return NON_FICTION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgARdK5lrApF"
   },
   "source": [
    "or it is long and has a `FAC` entitity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJvs8-blXCUR"
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def is_long_and_has_fac(x):\n",
    "    if len(x.doc) > 50 and any([ent.label_ == \"FAC\" for ent in x.doc.ents]):\n",
    "        return NON_FICTION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBcGBar6rApF"
   },
   "source": [
    "We now have a bunch of labeling functions we'll create a new list containing these and see how they do.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "as9JuJAEI_CC"
   },
   "outputs": [],
   "source": [
    "lfs = [\n",
    "    lf_contains_novel,\n",
    "    lf_is_long_title,\n",
    "    keyword_tale,\n",
    "    keyword_poem,\n",
    "    has_many_org,\n",
    "    has_many_loc,\n",
    "    has_many_gpe,\n",
    "    has_law,\n",
    "    is_long_and_has_date,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdTrN2eQJNv3",
    "outputId": "12c7d7fd-048f-4742-da7e-9039bfef4ce0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3262/3262 [00:34<00:00, 93.42it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "22zdF0QFJQdm",
    "outputId": "6b9f4a25-44c0-48ba-fabf-e97d33132010"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_contains_novel</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.058553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_is_long_title</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_tale</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.043532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_poem</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_org</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_loc</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_gpe</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_law</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_long_and_has_date</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_contains_novel     0      [0]  0.058553  0.000000        0.0\n",
       "lf_is_long_title      1      [1]  0.023299  0.011036        0.0\n",
       "keyword_tale          2      [0]  0.043532  0.000000        0.0\n",
       "keyword_poem          3      [0]  0.042918  0.000000        0.0\n",
       "has_many_org          4      [1]  0.011956  0.011956        0.0\n",
       "has_many_loc          5      [1]  0.011036  0.011036        0.0\n",
       "has_many_gpe          6      [1]  0.011036  0.011036        0.0\n",
       "has_law               7      [1]  0.004905  0.000000        0.0\n",
       "is_long_and_has_date  8      [1]  0.003372  0.003372        0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGN7F9CRrApG"
   },
   "source": [
    "Again our coverage is quite low but we also don't have too many conflicts. We can check the performance of these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dHGSVqiJU3M",
    "outputId": "94925eb2-e4be-48e8-9942-95b7f691d4d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.94736842, 0.97183099, 1.        , 0.92307692,\n",
       "       0.91666667, 0.91666667, 1.        , 1.        ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_empirical_accuracies(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-iq7pyqrApG"
   },
   "source": [
    "These are all doing pretty good so we might be okay with lower coverage for now. We also have a resource available to us which should boost our coverage a fair bit: our previously trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caLGF1CiPnB7"
   },
   "source": [
    "## Using our previous model \n",
    "\n",
    "In a previously notebook we trained a model which didn't perform terribly. Although we wanted to improve the performance, hence this notebook, it wasn't so disastrous as to be unusable, particularly with the insights we got from the error analysis notebook that if we raise the threshold of confidence for which we accept our models predictions our performance increases quite a bit. We may therefore want to try and incorporate this model as another way of labeling more data. \n",
    "\n",
    "There are various ways in which we can do this, we'll look at one approach below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwU6Rn2YrApH"
   },
   "source": [
    "We'll start by importing fastai so we can load our previously trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hgtdCZPRZ3g"
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB36e6yerApH"
   },
   "source": [
    "If you don't have a model saved from notebook you can download one by uncommenting the below cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5RY9B_wt5gr",
    "outputId": "cf414e0a-129a-425b-edd5-d9d0365d1c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-11 14:12:20--  https://zenodo.org/record/5245175/files/20210928-model.pkl?download=1\n",
      "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
      "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 158529715 (151M) [application/octet-stream]\n",
      "Saving to: ‘20210928-model.pkl’\n",
      "\n",
      "20210928-model.pkl  100%[===================>] 151.19M  11.1MB/s    in 16s     \n",
      "\n",
      "2021-11-11 14:12:38 (9.54 MB/s) - ‘20210928-model.pkl’ saved [158529715/158529715]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget -O 20210928-model.pkl  https://zenodo.org/record/5245175/files/20210928-model.pkl?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCOuI9wiSkcj"
   },
   "outputs": [],
   "source": [
    "learn = load_learner(\"20210928-model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6ZwD9Y8rApH"
   },
   "source": [
    "We can quickly check our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH0SBvmtWOPi",
    "outputId": "0cc02e67-6230-452d-f3fd-1fea07ce80c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fiction', 'Non-fiction']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.dls.vocab[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bVWLC6mhinN"
   },
   "source": [
    "One way of using this model would be to create a preprocessor that will be used by Snorkel. This will do the setup required to use this model (as we saw with the spaCy example). We can do this by using the `preprocessor` decorator. Our function then calls whatever we need to happen. In this case we store the predicted label and probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFcZ7HdeT0GK"
   },
   "outputs": [],
   "source": [
    "# from snorkel.preprocess import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZbBQ9PaRLwV"
   },
   "outputs": [],
   "source": [
    "# @preprocessor(memoize=True)\n",
    "# def fastai_pred(x):\n",
    "#     with learn.no_bar():\n",
    "#         *_, probs = learn.predict(x.title)\n",
    "#     x.fiction_prob = probs[0]\n",
    "#     x.non_fiction_prob = probs[1]\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bftEQU-Ihkeh"
   },
   "source": [
    "In this example we don't want to use this since we then don't benefit from doing our inference in batches. Instead we'll just create some new columns to store our fastai models labels and confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "b3UnA2vksMRT",
    "outputId": "ca9bd9f6-9789-411e-9f63-33d668def900"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = learn.dls.test_dl(df.Title)\n",
    "preds = learn.get_preds(dl=test_dl)\n",
    "fiction_prob, non_fiction_prob = np.hsplit(preds[0].numpy(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQEl5FiWsvkJ",
    "outputId": "31d2d515-453e-4bae-cb2d-4a977f7250b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999399 ],\n",
       "       [0.9999399 ],\n",
       "       [0.9999399 ],\n",
       "       ...,\n",
       "       [0.04363291],\n",
       "       [0.04363291],\n",
       "       [0.02832149]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiction_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGNGHrnPsZLv"
   },
   "outputs": [],
   "source": [
    "df[\"fiction_prob\"] = fiction_prob\n",
    "df[\"non_fiction_prob\"] = non_fiction_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2lda_ytrApK"
   },
   "source": [
    "We now have some new columns containing the probabilities for our labels from our previously created model. \n",
    "\n",
    "We saw in the previous [](02_error_analysis.ipynb) section that by only using predictions where our model was confident, we could get better results i.e. we only accept suggestions from our model where it is very confident. For example, we could accept a prediction only if it is above 95% confidence. \n",
    "\n",
    "We'll use this in our labelling function to set a threshold at which we accept the previous models predictions. If the model is unsure we don't use it's prediction. This will mean less of our data ends up labelled because some predictions aren't used. However, we will hopefully get *better* predictions because we only use those where our model is confident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ATiupkWRLsC"
   },
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def fastai_fiction_prob_v_high(x):\n",
    "    return FICTION if x.fiction_prob > 0.97 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RaEdWmKHUzpM"
   },
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def fastai_non_fiction_prob_v_high(x):\n",
    "    return NON_FICTION if x.non_fiction_prob > 0.97 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww-pfEAIrApM"
   },
   "source": [
    "Again we add this to our existing labeling function list and apply it to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nY0VgTlxUEbG"
   },
   "outputs": [],
   "source": [
    "lfs += [fastai_fiction_prob_v_high, fastai_non_fiction_prob_v_high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4jEu28OULT_",
    "outputId": "9e7afdb8-9091-40ce-e110-e984a3aa67d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabelingFunction lf_contains_novel, Preprocessors: [],\n",
       " LabelingFunction lf_is_long_title, Preprocessors: [],\n",
       " LabelingFunction keyword_tale, Preprocessors: [],\n",
       " LabelingFunction keyword_poem, Preprocessors: [],\n",
       " LabelingFunction has_many_org, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],\n",
       " LabelingFunction has_many_loc, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],\n",
       " LabelingFunction has_many_gpe, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],\n",
       " LabelingFunction has_law, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],\n",
       " LabelingFunction is_long_and_has_date, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],\n",
       " LabelingFunction fastai_fiction_prob_v_high, Preprocessors: [],\n",
       " LabelingFunction fastai_non_fiction_prob_v_high, Preprocessors: []]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wD4qlyErUL7k",
    "outputId": "e9afc6df-ff39-45ca-d8ce-49aab7a88605"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3262/3262 [00:34<00:00, 95.06it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "ocBnVr7LZggU",
    "outputId": "0967702e-d1ce-4c2a-b8d2-bdfc5714eb54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_contains_novel</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.058553</td>\n",
       "      <td>0.056101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_is_long_title</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_tale</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.043532</td>\n",
       "      <td>0.034028</td>\n",
       "      <td>0.000613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_poem</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.035561</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_org</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_loc</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_gpe</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_law</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_long_and_has_date</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastai_fiction_prob_v_high</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.223483</td>\n",
       "      <td>0.125996</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastai_non_fiction_prob_v_high</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.338749</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.000613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_contains_novel                0      [0]  0.058553  0.056101   0.000000\n",
       "lf_is_long_title                 1      [1]  0.023299  0.019926   0.000000\n",
       "keyword_tale                     2      [0]  0.043532  0.034028   0.000613\n",
       "keyword_poem                     3      [0]  0.042918  0.035561   0.000000\n",
       "has_many_org                     4      [1]  0.011956  0.011956   0.000920\n",
       "has_many_loc                     5      [1]  0.011036  0.011036   0.000920\n",
       "has_many_gpe                     6      [1]  0.011036  0.011036   0.000920\n",
       "has_law                          7      [1]  0.004905  0.002759   0.000000\n",
       "is_long_and_has_date             8      [1]  0.003372  0.003372   0.000000\n",
       "fastai_fiction_prob_v_high       9      [0]  0.223483  0.125996   0.000920\n",
       "fastai_non_fiction_prob_v_high  10      [1]  0.338749  0.021153   0.000613"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agzf-b61rApN"
   },
   "source": [
    "We can see that the labelling function which uses our model outputs has a much higher coverage of our data. This should be very helpful in labelling more examples but we want to check that these are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7aIyIm3UWaU",
    "outputId": "d439b024-d8a5-4a53-973c-614cb51c4f9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.94736842, 0.97183099, 1.        , 0.92307692,\n",
       "       0.91666667, 0.91666667, 1.        , 1.        , 0.99314129,\n",
       "       0.99909502])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_empirical_accuracies(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHuFzdcLrApO"
   },
   "source": [
    "We can see that our labels all perform pretty well i.e. above 90%. We are also getting much better coverage now that we leverage our existing model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoM_W7jyWFGG"
   },
   "source": [
    "## Creating more training data\n",
    "\n",
    "So far we have been using the validation data to develop some potential labeling functions. Now we are fairly satisfied with them let's apply to the full data. We'll quickly look at this process on our current data and then we'll move to the full metadata json file that we use for creating more training data. \n",
    "\n",
    "We use `LabelModel` to fit a model which will be able to take as input all of the predictions from our labelling functions and fit a model which will predict the probability for a label. This model is able to deal with some conflicts between labeling functions and will do much better in most cases than a naive majority vote model i.e. one which just accepts the most often predicted label. The details of this model are beyond the scope of this notebook but if you are interested *Data Programming: Creating Large Training Sets, Quickly* offers a fuller overview of the details of this method{cite:ps}`NIPS2016_6709e8d6` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-obCpwvJZ8w"
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88KeKWd0rApO"
   },
   "source": [
    "Above we fit our `LabelModel` for 500 epochs. Since we are working with the training set still we can get the score for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IGGOpuCLPSX",
    "outputId": "17051cd0-333d-43b9-f912-db38d42d19b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.994250331711632,\n",
       " 'precision': 0.9964539007092199,\n",
       " 'recall': 0.9920564872021183}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model.score(\n",
    "    L=L_train,\n",
    "    Y=ground_truth,\n",
    "    tie_break_policy=\"abstain\",\n",
    "    metrics=[\"precision\", \"recall\", \"f1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCfWattQrApP"
   },
   "source": [
    "This is looking pretty good and hopefully this performance will be similar for our full data. We'll now load a dataframe that includes all of the BL books metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlp1BJtOMbOi"
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\n",
    "    \"https://bl.iro.bl.uk/downloads/e1be1324-8b1a-4712-96a7-783ac209ddef?locale=en\",\n",
    "    dtype=dtypes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxZ7LEdUrApP"
   },
   "source": [
    "We create a new column `text_len` since we need this for some of our labeling functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8EhPvf_Mtk-"
   },
   "outputs": [],
   "source": [
    "df_full[\"text_len\"] = df_full.Title.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuwazKYrrApQ"
   },
   "source": [
    "We also get our fastai model's predictions into new columns. This obviously takes some time since we're now doing inference on a fairly large dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "qD-9iw8utG6p",
    "outputId": "a53c2302-412f-4f17-e732-c5abad892d8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dl = learn.dls.test_dl(df_full.Title)\n",
    "preds = learn.get_preds(dl=test_dl)\n",
    "fiction_prob, non_fiction_prob = np.hsplit(preds[0].numpy(), 2)\n",
    "df_full[\"fiction_prob\"] = fiction_prob\n",
    "df_full[\"non_fiction_prob\"] = non_fiction_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PR6gTlHHrApQ"
   },
   "source": [
    "Now we have all the same columns in place as we had previously we can now apply our labelling functions to all of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQV0ddZzMfDk",
    "outputId": "78d96fb0-a37f-4925-ebf5-a7dd09f0ba6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52695/52695 [09:27<00:00, 92.85it/s] \n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnvUYY44rApQ"
   },
   "source": [
    "We can check what the coverage, overlaps and conflicts look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "FVvOgMdZM8vn",
    "outputId": "e6da6877-dd17-40a1-b1a4-a9f36d3d274e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_contains_novel</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.000285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_is_long_title</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.047367</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.003036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_tale</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.022165</td>\n",
       "      <td>0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_poem</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.089952</td>\n",
       "      <td>0.049018</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_org</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.021520</td>\n",
       "      <td>0.021520</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_loc</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_gpe</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_law</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.000531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_long_and_has_date</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastai_fiction_prob_v_high</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.213834</td>\n",
       "      <td>0.122858</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastai_non_fiction_prob_v_high</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.192599</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.000683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_contains_novel                0      [0]  0.066875  0.057178   0.000285\n",
       "lf_is_long_title                 1      [1]  0.047367  0.032413   0.003036\n",
       "keyword_tale                     2      [0]  0.036702  0.022165   0.001006\n",
       "keyword_poem                     3      [0]  0.089952  0.049018   0.002619\n",
       "has_many_org                     4      [1]  0.021520  0.021520   0.001974\n",
       "has_many_loc                     5      [1]  0.021008  0.021008   0.001917\n",
       "has_many_gpe                     6      [1]  0.021008  0.021008   0.001917\n",
       "has_law                          7      [1]  0.004232  0.002106   0.000531\n",
       "is_long_and_has_date             8      [1]  0.007762  0.007762   0.000380\n",
       "fastai_fiction_prob_v_high       9      [0]  0.213834  0.122858   0.000626\n",
       "fastai_non_fiction_prob_v_high  10      [1]  0.192599  0.019015   0.000683"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joUVFtNprApR"
   },
   "source": [
    "The coverage is lower than we had previously. This makes sense since we previously used the same data for developing our labeling functions as we used for training our model. It's not suprising our model is more confident about these. If we were being more dilligent we might have held back a different dataset for developing our labelling functions but since we're being a bit pragmatic (lazy) here we won't worry too much about this. We can again fit our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyHqeNpQM2UO"
   },
   "outputs": [],
   "source": [
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvVAxqo8rApR"
   },
   "source": [
    "We now use this model to predict the probabilites from our labelling function outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JC-pRGHIOR0T"
   },
   "outputs": [],
   "source": [
    "probs_train = label_model.predict_proba(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUYusacNrApS"
   },
   "source": [
    "We currently have predictions for some of our data but not all of it. Since we want only the labelled exampled we use a function from Snorkel to filter out data which our labeling functions didn't annotate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4YssthWMj_7"
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_full, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjffs_hPrApS"
   },
   "source": [
    "We now have the predicted probabilty for each label. We could work with these probabilities but to keep things simple we'll make these hard predictions i.e. fiction or non-fiction rather than 0.87% fiction. Again Snorkel provides a handy function for doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAokH_KaNqYo"
   },
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6pXG3YhrApS"
   },
   "source": [
    "Let's see how much data we have now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mwLQWQg5NJx",
    "outputId": "7e086537-d97b-493e-d3ff-bc63f0bb940c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26566"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ekPuSr9rApS"
   },
   "source": [
    "As a reminder we previosuly had `3262` labeled examples. We can see that we've now gained a lot more examples for relateively little work (especially if we compare how much time it would take to annotate these by hand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phmd7e4BrApT",
    "outputId": "b179d845-3747-48b9-cec1-e83924487ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.144083384426732"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26566 / 3262"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfCrg9hMrApT"
   },
   "source": [
    "We'll store out new labels in a label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpvkS-jaemzJ",
    "outputId": "6d769293-fd91-45b9-dfa5-c7a08228143f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train_filtered[\"snorkel_label\"] = preds_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1l5ISuOmBZ2d",
    "outputId": "0e8a76a4-ac81-43a9-da2a-7b35fc310204"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "8        0\n",
       "        ..\n",
       "52682    0\n",
       "52689    0\n",
       "52692    0\n",
       "52693    0\n",
       "52694    0\n",
       "Name: snorkel_label, Length: 26566, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered[\"snorkel_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwSW3Kb7rApT"
   },
   "source": [
    "## Creating our new training data\n",
    "\n",
    "As a reminder of what we've done:\n",
    "\n",
    "- we had training data/annotations collected via a zooniverse crowdsourcing task with `2909` labeled examples in our validation set\n",
    "- we had previously used this to train a model that did fairly well \n",
    "- we used our existing training data to generate labeling functions, these leveraged:\n",
    "    - our intuitions about our data\n",
    "    - SpaCy models\n",
    "    - our previous model\n",
    "- we applied these labeling functions to the Microsoft Digitised Books file. Once we excluded examples which weren't labeled by our labeling functions we had `34542` labeled examples we could work with. \n",
    "\n",
    "We now want to get all of this data into a format we can use to train new models with. There are a few things we need to do for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5FMQGMnCWr0"
   },
   "source": [
    "### Map to our original labels\n",
    "We'll map these back to our original fiction and non-fiction labels. This isn't super important but might be more explicit then `1` or `0` for our labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2194mFbBeI8S",
    "outputId": "138b0473-3c06-49b8-c708-c26a0548c482"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train_filtered[\"snorkel_genre\"] = df_train_filtered[\"snorkel_label\"].map(\n",
    "    {0: \"Fiction\", 1: \"Non-fiction\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "toI1t3TOH8RZ",
    "outputId": "42e29e62-69cb-4125-a718-3f0b66df01ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BL record ID', 'Type of resource', 'Name',\n",
       "       'Dates associated with name', 'Type of name', 'Role', 'All names',\n",
       "       'Title', 'Variant titles', 'Series title', 'Number within series',\n",
       "       'Country of publication', 'Place of publication', 'Publisher',\n",
       "       'Date of publication', 'Edition', 'Physical description',\n",
       "       'Dewey classification', 'BL shelfmark', 'Topics', 'Genre', 'Languages',\n",
       "       'Notes', 'BL record ID for physical resource', 'text_len',\n",
       "       'fiction_prob', 'non_fiction_prob', 'snorkel_label', 'snorkel_genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptHsNab4imbn"
   },
   "source": [
    "### Selecting required columns \n",
    "\n",
    "Since we have only been using the title and the label (fiction or non-fiction) to train our models we will just keep these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7G4MY74F1WWd",
    "outputId": "13d27f1b-e163-4daa-e8fd-fd84aa6db943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Fiction\n",
       "1           Fiction\n",
       "2           Fiction\n",
       "3           Fiction\n",
       "4           Fiction\n",
       "           ...     \n",
       "3257    Non-fiction\n",
       "3258    Non-fiction\n",
       "3259    Non-fiction\n",
       "3260    Non-fiction\n",
       "3261    Non-fiction\n",
       "Name: annotator_genre, Length: 3262, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"annotator_genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3yoxnYg82GX"
   },
   "outputs": [],
   "source": [
    "df[\"snorkel_genre\"] = df[\"annotator_genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10c45HFJz6Bq"
   },
   "outputs": [],
   "source": [
    "df_snorkel_train = pd.concat([df, df_train_filtered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nt5kKsDWF7px",
    "outputId": "a59eb38c-0dd0-45f7-e50e-9ec1129ecb5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fiction        15840\n",
       "Non-fiction    13988\n",
       "Name: snorkel_genre, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snorkel_train[\"snorkel_genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddUaF9uerVep"
   },
   "source": [
    "### Prioritising human annotations\n",
    "\n",
    "When we applied our labeling functions across the full Microsoft Digitised Books metadata file we didn't do anything to exclude titles where a human annotator had already provided a label as part of the Zooniverse annotation task. Since we joined the full metadata and the human annotations together we will now have some duplicates. We almost definitely want to prioritise the human annotations over our label function labels. We could use Pandas drop_duplicates and keep the first example (the human annotated one) to deal with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "athSNKLOraYa",
    "outputId": "50cb4887-fabd-4ca3-b37e-f57a2ffee736"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "52682    False\n",
       "52689    False\n",
       "52692    False\n",
       "52693    False\n",
       "52694    False\n",
       "Length: 29828, dtype: bool"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snorkel_train.duplicated(subset=\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lVtbmKXycl0"
   },
   "outputs": [],
   "source": [
    "df_snorkel_train = df_snorkel_train.drop_duplicates(subset=\"Title\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8t9T_nEKyciA",
    "outputId": "b0954427-2087-450e-a7ed-a8c0e85f52b9",
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BL record ID</th>\n",
       "      <th>Type of resource</th>\n",
       "      <th>Name</th>\n",
       "      <th>Dates associated with name</th>\n",
       "      <th>Type of name</th>\n",
       "      <th>Role</th>\n",
       "      <th>All names</th>\n",
       "      <th>Title</th>\n",
       "      <th>Variant titles</th>\n",
       "      <th>Series title</th>\n",
       "      <th>Number within series</th>\n",
       "      <th>Country of publication</th>\n",
       "      <th>Place of publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Date of publication</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Physical description</th>\n",
       "      <th>Dewey classification</th>\n",
       "      <th>BL shelfmark</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Notes</th>\n",
       "      <th>BL record ID for physical resource</th>\n",
       "      <th>classification_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>subject_ids</th>\n",
       "      <th>annotator_date_pub</th>\n",
       "      <th>annotator_normalised_date_pub</th>\n",
       "      <th>annotator_edition_statement</th>\n",
       "      <th>annotator_genre</th>\n",
       "      <th>annotator_FAST_genre_terms</th>\n",
       "      <th>annotator_FAST_subject_terms</th>\n",
       "      <th>annotator_comments</th>\n",
       "      <th>annotator_main_language</th>\n",
       "      <th>annotator_other_languages_summaries</th>\n",
       "      <th>annotator_summaries_language</th>\n",
       "      <th>annotator_translation</th>\n",
       "      <th>annotator_original_language</th>\n",
       "      <th>annotator_publisher</th>\n",
       "      <th>annotator_place_pub</th>\n",
       "      <th>annotator_country</th>\n",
       "      <th>annotator_title</th>\n",
       "      <th>Link to digitised book</th>\n",
       "      <th>annotated</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text_len</th>\n",
       "      <th>fiction_prob</th>\n",
       "      <th>non_fiction_prob</th>\n",
       "      <th>snorkel_genre</th>\n",
       "      <th>snorkel_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014616539</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hazlitt, William Carew, 1834-1913 [person]</td>\n",
       "      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>\n",
       "      <td>Single Works</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Ballantyne, Hanson</td>\n",
       "      <td>1877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 pages (4°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 11651.h.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000206670</td>\n",
       "      <td>263940444.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-07-27 07:35:13 UTC</td>\n",
       "      <td>44330917.0</td>\n",
       "      <td>1877</td>\n",
       "      <td>1877</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ballantyne Hanson &amp; Co.</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>stk</td>\n",
       "      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>\n",
       "      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F718</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>014616561</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Bingham, Ashton, Mrs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bingham, Ashton, Mrs [person]</td>\n",
       "      <td>The Autumn Leaf Poems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Colston</td>\n",
       "      <td>1891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vi, 104 pages (8°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 011649.e.105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000353271</td>\n",
       "      <td>268728281.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-08-18 07:02:17 UTC</td>\n",
       "      <td>44331070.0</td>\n",
       "      <td>1891</td>\n",
       "      <td>1891</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colston &amp; Company</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>stk</td>\n",
       "      <td>The Autumn Leaf Poems</td>\n",
       "      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F04C</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>0.999486</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>014616607</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Cartwright, William</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>writer</td>\n",
       "      <td>Cartwright, William, writer [person]</td>\n",
       "      <td>The Battle of Waterloo, a poem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>Longman</td>\n",
       "      <td>1827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vii, 71 pages (8°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 992.i.26</td>\n",
       "      <td>Waterloo, Battle of (Belgium : 1815)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000621918</td>\n",
       "      <td>263935396.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-07-27 06:39:57 UTC</td>\n",
       "      <td>44331748.0</td>\n",
       "      <td>1827</td>\n",
       "      <td>1827</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>\n",
       "      <td>647 7 $aBattle of Waterloo$c(Waterloo, Belgium :$d1815)$2fast$0(OCoLC)fst01172689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Longman, Rees, Orme, Brown &amp; Green\\nBurlton\\nMerricks</td>\n",
       "      <td>London\\nLeominster\\nHereford</td>\n",
       "      <td>enk</td>\n",
       "      <td>The Battle of Waterloo, a poem</td>\n",
       "      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002ED4C</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>0.991599</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>014616686</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Earle, John Charles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Earle, John Charles [person]</td>\n",
       "      <td>Maximilian, and other poems, etc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 11648.i.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poetry or verse</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001025896</td>\n",
       "      <td>265570129.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-08-03 07:25:30 UTC</td>\n",
       "      <td>44331725.0</td>\n",
       "      <td>1868</td>\n",
       "      <td>1868</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burns, Oates, &amp; Co.</td>\n",
       "      <td>London</td>\n",
       "      <td>enk</td>\n",
       "      <td>Maximilian, and other poems, etc</td>\n",
       "      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F2AA</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>0.982546</td>\n",
       "      <td>0.017454</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>014616696</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fabellæ mostellariæ: or Devonshire and Wiltshire stories in verse; including specimens of the Devonshire dialect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>Exeter ; London</td>\n",
       "      <td>Hamilton, Adams ; Henry S. Eland</td>\n",
       "      <td>1878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77 pages (8°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 11652.h.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001187981</td>\n",
       "      <td>269169228.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-08-20 12:32:34 UTC</td>\n",
       "      <td>44331389.0</td>\n",
       "      <td>1878</td>\n",
       "      <td>1878</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamilton, Adams, and Co.\\nHenry S. Eland</td>\n",
       "      <td>London\\nExeter</td>\n",
       "      <td>enk</td>\n",
       "      <td>Fabellæ mostellariæ: or Devonshire and Wiltshire stories in verse; including specimens of the Devonshire dialect</td>\n",
       "      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F90A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>112</td>\n",
       "      <td>0.983944</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52682</th>\n",
       "      <td>016289050</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Hastings, Beatrice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hastings, Beatrice [person]</td>\n",
       "      <td>The maids' comedy. A chivalric romance in thirteen chapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>Stephen Swift</td>\n",
       "      <td>1911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199 pages, 20 cm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 012618.c.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Anonymous. By Beatrice Hastings</td>\n",
       "      <td>004111105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>0.999444</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52689</th>\n",
       "      <td>016289057</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Garstang, Walter, M.A., F.Z.S.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garstang, Walter, M.A., F.Z.S. [person] ; Shepherd, J. A. (James Affleck), 1867-approximately 1931 [person]</td>\n",
       "      <td>Songs of the Birds ... With illustrations by J.A. Shepherd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>John Lane</td>\n",
       "      <td>1922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101 pages, illustrations (8°)</td>\n",
       "      <td>598.259</td>\n",
       "      <td>Digital Store 011648.g.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Poems, with and introductory essay</td>\n",
       "      <td>004158005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>0.993942</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52692</th>\n",
       "      <td>016289060</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Wellesley, Dorothy</td>\n",
       "      <td>1889-1956</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wellesley, Dorothy, 1889-1956 [person]</td>\n",
       "      <td>Early Poems. By M. A [i.e. Dorothy Violet Wellesley, Lady Gerald Wellesley.]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>Elkin Mathews</td>\n",
       "      <td>1913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vii, 90 pages (8°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 011649.eee.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000000839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>0.987218</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52693</th>\n",
       "      <td>016289061</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>A, T. H. E.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A, T. H. E. [person]</td>\n",
       "      <td>Of Life and Love [Poems.] By T. H. E. A, writer of 'The Message.'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>J. M. Watkins</td>\n",
       "      <td>1924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89 pages (8°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 011645.e.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000001167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>0.977032</td>\n",
       "      <td>0.022968</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52694</th>\n",
       "      <td>016289062</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Abbay, Richard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbay, Richard [person]</td>\n",
       "      <td>Life, a Mode of Motion; or, He and I, my two selves [A poem.]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>Jarrold</td>\n",
       "      <td>1919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volumes, 58 pages (8°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 011649.g.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000003140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>0.975888</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25683 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BL record ID Type of resource  ... snorkel_genre snorkel_label\n",
       "0        014616539        Monograph  ...       Fiction           NaN\n",
       "5        014616561        Monograph  ...       Fiction           NaN\n",
       "10       014616607        Monograph  ...       Fiction           NaN\n",
       "15       014616686        Monograph  ...       Fiction           NaN\n",
       "20       014616696        Monograph  ...       Fiction           NaN\n",
       "...            ...              ...  ...           ...           ...\n",
       "52682    016289050        Monograph  ...       Fiction           0.0\n",
       "52689    016289057        Monograph  ...       Fiction           0.0\n",
       "52692    016289060        Monograph  ...       Fiction           0.0\n",
       "52693    016289061        Monograph  ...       Fiction           0.0\n",
       "52694    016289062        Monograph  ...       Fiction           0.0\n",
       "\n",
       "[25683 rows x 52 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snorkel_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAbny44me1kh"
   },
   "source": [
    "## Data leakage \n",
    "\n",
    "Want to exclude data which is in test set so we drop these examples from our training data. Since we care about titles 'leaking' we look up whether any titles in our training data appear in our test data and remove these from the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkuWjE3TWaan"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_errors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aa2zEKM8L3MU"
   },
   "source": [
    "### Removing data which is in our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75MlG5gjWXc4"
   },
   "outputs": [],
   "source": [
    "df_snorkel_train = df_snorkel_train[~df_snorkel_train.Title.isin(df_test.title)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEFkhfPUa9-t",
    "outputId": "00f8fdea-bdda-4e88-aacd-c195e798fed3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25683"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_snorkel_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB71yYWMrApV"
   },
   "source": [
    "### Creating new splits\n",
    "\n",
    "We create some new splits following the same process we used before. We can then use these splits to more accurately compare across models training using this dataset. Since we have kept the test data out of our 'Snorkel dataset' we will also continue to use this test data for final model evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAlOyTpCM9TZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-siZtOQIOrc"
   },
   "outputs": [],
   "source": [
    "train_inds, valid_ins = next(\n",
    "    GroupShuffleSplit(n_splits=2, test_size=0.2).split(\n",
    "        df_snorkel_train, groups=df_snorkel_train[\"Title\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDsWIpsGM6kT"
   },
   "outputs": [],
   "source": [
    "df_train, df_valid = (\n",
    "    df_snorkel_train.iloc[train_inds].copy(),\n",
    "    df_snorkel_train.iloc[valid_ins].copy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvDIwam0Mbop"
   },
   "outputs": [],
   "source": [
    "df_train[\"is_valid\"] = False\n",
    "df_valid[\"is_valid\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNBbfN9YNiwt"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPrSyqF8Hdxx",
    "outputId": "2b07406c-8241-48fb-a522-74eafb68d6c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fiction        13918\n",
       "Non-fiction    11765\n",
       "Name: snorkel_genre, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.snorkel_genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzk11B5zrApX"
   },
   "source": [
    "We can see we still have a healthy number of examples to train our model on even after dropping titles which appear in our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vin0K1-vh_X9",
    "outputId": "fcfde1bf-012d-4e5c-eda6-1d63adff1001"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25683"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAE7tn2xrApX"
   },
   "source": [
    "## Saving our new training data\n",
    "\n",
    "We'll save our new training data as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wwPG1gWk5Ab"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/snorkel_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "1SywpYsZ1CrV",
    "outputId": "af9a3344-ca7d-4985-cb61-f5bdf7a6df0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BL record ID</th>\n",
       "      <th>Type of resource</th>\n",
       "      <th>Name</th>\n",
       "      <th>Dates associated with name</th>\n",
       "      <th>Type of name</th>\n",
       "      <th>Role</th>\n",
       "      <th>All names</th>\n",
       "      <th>Title</th>\n",
       "      <th>Variant titles</th>\n",
       "      <th>Series title</th>\n",
       "      <th>Number within series</th>\n",
       "      <th>Country of publication</th>\n",
       "      <th>Place of publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Date of publication</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Physical description</th>\n",
       "      <th>Dewey classification</th>\n",
       "      <th>BL shelfmark</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Notes</th>\n",
       "      <th>BL record ID for physical resource</th>\n",
       "      <th>classification_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>subject_ids</th>\n",
       "      <th>annotator_date_pub</th>\n",
       "      <th>annotator_normalised_date_pub</th>\n",
       "      <th>annotator_edition_statement</th>\n",
       "      <th>annotator_genre</th>\n",
       "      <th>annotator_FAST_genre_terms</th>\n",
       "      <th>annotator_FAST_subject_terms</th>\n",
       "      <th>annotator_comments</th>\n",
       "      <th>annotator_main_language</th>\n",
       "      <th>annotator_other_languages_summaries</th>\n",
       "      <th>annotator_summaries_language</th>\n",
       "      <th>annotator_translation</th>\n",
       "      <th>annotator_original_language</th>\n",
       "      <th>annotator_publisher</th>\n",
       "      <th>annotator_place_pub</th>\n",
       "      <th>annotator_country</th>\n",
       "      <th>annotator_title</th>\n",
       "      <th>Link to digitised book</th>\n",
       "      <th>annotated</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text_len</th>\n",
       "      <th>fiction_prob</th>\n",
       "      <th>non_fiction_prob</th>\n",
       "      <th>snorkel_genre</th>\n",
       "      <th>snorkel_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014616539</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hazlitt, William Carew, 1834-1913 [person]</td>\n",
       "      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>\n",
       "      <td>Single Works</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Ballantyne, Hanson</td>\n",
       "      <td>1877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 pages (4°)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Digital Store 11651.h.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000206670</td>\n",
       "      <td>263940444.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-07-27 07:35:13 UTC</td>\n",
       "      <td>44330917.0</td>\n",
       "      <td>1877</td>\n",
       "      <td>1877</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ballantyne Hanson &amp; Co.</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>stk</td>\n",
       "      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>\n",
       "      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F718</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99994</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BL record ID Type of resource  ... snorkel_genre snorkel_label\n",
       "0    014616539        Monograph  ...       Fiction           NaN\n",
       "\n",
       "[1 rows x 52 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTvwIXSdiAPs"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "We now have a larger training set which includes both our original training data produced through crowdsourcing plus our training data we generated using our labeling functions and the Snorkel library. \n",
    "\n",
    "Hopefully having more training data will result in being able to improve the models we can generate. In the next sections we'll look at two approaches we can use for doing this:\n",
    "- training the same model as before but with more data\n",
    "- training a transformer based model with more data\n",
    "\n",
    "We will hopefully see some improvements now we have more data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCAWABEsrApY"
   },
   "source": [
    ":::{note}\n",
    "The main things we tried to show in this notebook:\n",
    "- we can leverage our domain knowledge to help generate training data using a programmatic data labeling approach\n",
    "- this approach can leverage existing training data generated by humans\n",
    "- we can often use existing models to help generate training data even if the task is quite different \n",
    ":::\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "04_snorkel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
