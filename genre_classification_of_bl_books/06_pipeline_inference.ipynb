{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our new Hugging Face model\n",
    "\n",
    "Now we have our new Hugging Face model available on the model hub we can use it as we would any other model on the hub ðŸ˜€\n",
    "\n",
    "## Install our required packages \n",
    "\n",
    "First we install our required packages. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glpkdXbVZdqU",
    "outputId": "0c1c0b4f-d249-49fe-8fb9-b1b262639964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tqdm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFLH4i2NZgLn"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZQ9AuF5iPXU"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our model and tokenizer \n",
    "\n",
    "We create a tokenizer and a model using the pre-trained model we created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZXvk6W-hyJx"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"davanstrien/bl-books-genre\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"davanstrien/bl-books-genre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the process of doing inference very straightforward we can use a [`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html). These are intended to make the process of using models for inference easy for a wide range of tasks. We need to tell the pipeline what kind of task we're doing and pass in our model and tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gQql5YSaxt5"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jj0nOcDFgqsX"
   },
   "outputs": [],
   "source": [
    "title = \"The Coal Fields of South Wales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pjRlGzvf2zU",
    "outputId": "415bb28f-7bd0-471e-99f3-e41a6f9966d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Non-fiction', 'score': 0.9989659786224365}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-GzMX4xfn1Y",
    "outputId": "5f0275fc-e49a-4697-fe33-3cca203e9c8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Fiction', 'score': 0.9980145692825317}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Oliver Twist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIep3ySnpE57"
   },
   "source": [
    "Now we essentially have a function that takes some text and returns some predictions. We can now predict against our full dataset. Since we're not going to be doing this over and over, we won't worry too much about the performance of our approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sN_9Yye8YWZL"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"MS digitised books 2021-01-09.csv\",\n",
    "    dtype={\n",
    "        \"BL record ID\": \"string\",\n",
    "        \"BL record ID for physical resource\": \"string\",\n",
    "        \"Title\": \"string\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnJbGVstpNTF",
    "outputId": "c65800bf-8364-44c8-9d4c-e52bd1369892"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52695"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "mnq7RnrXpU5l",
    "outputId": "a496cdc3-cb9c-4ba6-dc9d-92b840b96690"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BL record ID</th>\n",
       "      <th>Type of resource</th>\n",
       "      <th>Name</th>\n",
       "      <th>Dates associated with name</th>\n",
       "      <th>Type of name</th>\n",
       "      <th>Role</th>\n",
       "      <th>All names</th>\n",
       "      <th>Title</th>\n",
       "      <th>Variant titles</th>\n",
       "      <th>Series title</th>\n",
       "      <th>Number within series</th>\n",
       "      <th>Country of publication</th>\n",
       "      <th>Place of publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Date of publication</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Physical description</th>\n",
       "      <th>Dewey classification</th>\n",
       "      <th>BL shelfmark</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Notes</th>\n",
       "      <th>BL record ID for physical resource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014602826</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Yearsley, Ann</td>\n",
       "      <td>1753-1806</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More, Hannah, 1745-1833 [person] ; Yearsley, A...</td>\n",
       "      <td>Poems on several occasions [With a prefatory l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1786</td>\n",
       "      <td>Fourth edition MANUSCRIPT note</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Store 11644.d.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003996603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BL record ID Type of resource  ... Notes BL record ID for physical resource\n",
       "0    014602826        Monograph  ...   NaN                          003996603\n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a function to try and get the prediction. It does a quick check to see if we need to chop off some of our text (our model has a max len of 512). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIcwiIyhp3Le"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-vBZanDpVew"
   },
   "outputs": [],
   "source": [
    "def try_predict(x):\n",
    "    pred = np.nan\n",
    "    if len(x) > 512:\n",
    "        x = x[:512]\n",
    "    try:\n",
    "        pred = classifier(x)\n",
    "    except Exception as e:\n",
    "        print(\"\\U0001F92E\", e, x)\n",
    "        pass\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite an ugly solution but since we're not planning to do anything beyond make these predictions once we'll allow a bit of sloppiness ðŸ˜‰. We can use `progress_apply` to get a little progress bar so we know how long it's going to take. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4f68630c71594502869f6d55283343d3",
      "b909c84ed9e941c3b218237255687782",
      "cecf9e32a8ec4bee93ce8ecd26f22994",
      "484530ea7e7d4bcd86b3f5401e00e59e",
      "045e1140903d421bb1f9532e4242c102",
      "8b5953da12e2487982ef79dafd4bd579",
      "a36bfbe094bf4ce0879a6530841aff46",
      "877f974b164041a2b5f4783cb8cdce92",
      "73d9e79f10a14303adac8d07f7d76c82",
      "814fa25439ad4e86936b04ff26fba21a",
      "c7c171bd644749fd8e521d6fb3f6b2af"
     ]
    },
    "id": "KgZvfniogw4l",
    "outputId": "cbf540ad-ac16-4d19-c631-3c11a89c20ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f68630c71594502869f6d55283343d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52695 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = df[\"Title\"].progress_apply(try_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XI-j28kl45-s",
    "outputId": "64de69c3-773b-4301-80ba-6d1b0e02b90a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Fiction', 'score': 0.9999717473983765}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcHPBTmwLKNa"
   },
   "source": [
    "We now just do a bit of tidying to get our labels into the format we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfMuIejUCoO9"
   },
   "outputs": [],
   "source": [
    "df[\"predicted_label\"] = preds.apply(lambda x: x[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zkuXxNWsQZyj",
    "outputId": "796d721b-3edc-49d1-c67b-0d2479a24bb6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Fiction'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predicted_label\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJtYTehVDRRk"
   },
   "outputs": [],
   "source": [
    "df[\"prob\"] = preds.apply(lambda x: x[0][\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NA0B_5iQ4gj"
   },
   "outputs": [],
   "source": [
    "def get_fiction_prob(x):\n",
    "    if x.predicted_label == \"Fiction\":\n",
    "        return x.prob\n",
    "    else:\n",
    "        return 1 - x.prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-ss3D8YQZlS"
   },
   "outputs": [],
   "source": [
    "df[\"fiction_probs\"] = df.apply(get_fiction_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgAi6gk0RiHB"
   },
   "outputs": [],
   "source": [
    "df[\"non_fiction_probs\"] = 1 - df[\"fiction_probs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZyeafJ9R3FV"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "y7eWz9mlUif_",
    "outputId": "640fd98d-50a0-4cc1-e90b-b34ff2f5e1f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BL record ID</th>\n",
       "      <th>Type of resource</th>\n",
       "      <th>Name</th>\n",
       "      <th>Dates associated with name</th>\n",
       "      <th>Type of name</th>\n",
       "      <th>Role</th>\n",
       "      <th>All names</th>\n",
       "      <th>Title</th>\n",
       "      <th>Variant titles</th>\n",
       "      <th>Series title</th>\n",
       "      <th>Number within series</th>\n",
       "      <th>Country of publication</th>\n",
       "      <th>Place of publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Date of publication</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Physical description</th>\n",
       "      <th>Dewey classification</th>\n",
       "      <th>BL shelfmark</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Notes</th>\n",
       "      <th>BL record ID for physical resource</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>fiction_probs</th>\n",
       "      <th>non_fiction_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014602826</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Yearsley, Ann</td>\n",
       "      <td>1753-1806</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More, Hannah, 1745-1833 [person] ; Yearsley, A...</td>\n",
       "      <td>Poems on several occasions [With a prefatory l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1786</td>\n",
       "      <td>Fourth edition MANUSCRIPT note</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Digital Store 11644.d.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>003996603</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BL record ID Type of resource  ... fiction_probs non_fiction_probs\n",
       "0    014602826        Monograph  ...      0.999972          0.000028\n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our updated metadata \n",
    "\n",
    "Now we can save our results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIDQ2RTIC0Rz"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/bl_books_w_genre_transformer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33878157",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "We have now got to the point where was have a version of the bl books metadata with a bunch of additional metadata. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "05_pipeline_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
