{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04b_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVmlzdje-VSZ"
      },
      "source": [
        "# Using a transformer based model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFosOAvpcIHE"
      },
      "source": [
        "We now have a larger dataset to work with. We previously said we wouldn't immediately jump to changing the model architecture we're using to improve our results but now we have some work on exploring our previous models errors and increasing the size of our training data we might want to see if working with a different type of model architecture improves our performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JtQm_s-cIHF"
      },
      "source": [
        "## Transformers \n",
        "\n",
        "Transformer based models have made a massive impact on the Natural Language Processing world. {cite:p}`vaswani2017attention`\n",
        "\n",
        "We won't dig into the deep details of how these architectures work here. If you want to learn more about how these models work there are lots of useful resources available including a free huggingface [course](https://huggingface.co/course). If you have a humanities background or interest you may also find the [Bert for Humanists](https://melaniewalsh.github.io/BERT-for-Humanists) project useful. \n",
        "\n",
        "One of the reasons we held of jumping straight to transformers is because of a more general concern with making sure we don't see machine learning as a process of optimising a model architecture but rather a process of trying to think about, and potentially improve our data in combination with choosing a model and improving the training process. \n",
        "\n",
        "The other slightly more practical reason we waited is that Transformer models are (in general) quite computationally expensive. If we are able to get sufficiently good performance using less computationally intensive methods then we might prefer to use those. With this said this can be overstated - again here we are not going to be training a model 'from scratch' (more on this shortly) but instead we will be fine-tuning an existing model. We can often do this with a single GPU and still get very good results. \n",
        "\n",
        "## The ðŸ¤— ecosystem  \n",
        "\n",
        "Hugging Face is a company which has made a massive impact on the NLP landscape over the past couple of years. It is focused on helping [\"Build, train and deploy state of the art models powered by the reference open source in natural language\"](https://huggingface.co/). One of the tools developed by Hugging Face is the [transformers](https://huggingface.co/transformers/) library. This library provides implementations of many transformer based models. This already provides us an easier way to access state of the art models without needing to implement and maintain them ourselves, however, one of the real benefits for us it the ability to use transformers in combination with models from the huggingface ['model hub'](huggingface.co/models). \n",
        "\n",
        "## The ðŸ¤— model hub\n",
        "\n",
        "We saw in previous notebooks how fine-tuning can be useful to reduce the amount of training data and compute resources  we need to build a useful model. This, arguably, becomes even more important for transformer based models which can be expensive to train. The Hugging Face ['model hub'](huggingface.co/models) gives us access to a huge number of pre-trained models ranging trained for a large number of tasks on a growing number of languages. \n",
        "\n",
        "\n",
        "```{image} figs/hub.png\n",
        ":alt: screenshot of hugginface hub\n",
        ":class: bg-primary mb-1\n",
        ":align: center\n",
        "```\n",
        "\n",
        "This means we can potentially find a model that already does something we want, or close to what we want. If we aren't lucky enough to find the exact model we need we can often find a model which will still work well on our task. \n",
        "\n",
        "We'll shortly see how we can also contribute to this model hub. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcMyZG5AcIHH"
      },
      "source": [
        "## blurr\n",
        "\n",
        "There are different ways we could use the [transformers](https://huggingface.co/transformers/) library. Since we already used fastai library in earlier parts of this notebook it might be nice to stick to this an API which is close to the fastai library. Fortunately for us [blurr](https://github.com/ohmeow/blurr) gives us exactly this blurr is a\n",
        "\n",
        "> [library that integrates huggingface transformers with version 2 of the fastai framework](https://github.com/ohmeow/blurr)\n",
        "\n",
        "## Install requirements "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBLvX1GpXvXl",
        "tags": [
          "hide-output"
        ],
        "outputId": "6b57c872-c981-4a4d-a145-6dc2b2378481"
      },
      "source": [
        "!pip install git+https://github.com/ohmeow/blurr.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ohmeow/blurr.git\n",
            "  Cloning https://github.com/ohmeow/blurr.git to /tmp/pip-req-build-r8_9rr9w\n",
            "  Running command git clone -q https://github.com/ohmeow/blurr.git /tmp/pip-req-build-r8_9rr9w\n",
            "Requirement already satisfied: torch<2.0.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (1.10.0+cu111)\n",
            "Requirement already satisfied: fastai>=2.4 in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (2.5.3)\n",
            "Requirement already satisfied: transformers>=4.6 in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (4.12.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (1.16.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (0.1.96)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (1.2.2)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (0.0.4)\n",
            "Requirement already satisfied: nbdev<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from ohmeow-blurr==0.1.2) (1.1.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (1.1.5)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (1.3.27)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (0.11.1+cu111)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (1.4.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (21.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (3.2.2)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (7.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (0.0.5)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai>=2.4->ohmeow-blurr==0.1.2) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress>=0.2.4->fastai>=2.4->ohmeow-blurr==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.1.3)\n",
            "Requirement already satisfied: nbconvert<6 in /usr/local/lib/python3.7/dist-packages (from nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.6.1)\n",
            "Requirement already satisfied: jupyter-client<7.0 in /usr/local/lib/python3.7/dist-packages (from nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.3.5)\n",
            "Requirement already satisfied: fastrelease in /usr/local/lib/python3.7/dist-packages (from nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.1.12)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (4.10.1)\n",
            "Requirement already satisfied: ghapi in /usr/local/lib/python3.7/dist-packages (from nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.1.19)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (4.9.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (22.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (2.8.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (4.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (2.6.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (2.0.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (2.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client<7.0->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (1.15.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (1.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai>=2.4->ohmeow-blurr==0.1.2) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.4->ohmeow-blurr==0.1.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.4->ohmeow-blurr==0.1.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.4->ohmeow-blurr==0.1.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai>=2.4->ohmeow-blurr==0.1.2) (3.0.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6->ohmeow-blurr==0.1.2) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6->ohmeow-blurr==0.1.2) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6->ohmeow-blurr==0.1.2) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6->ohmeow-blurr==0.1.2) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6->ohmeow-blurr==0.1.2) (0.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai>=2.4->ohmeow-blurr==0.1.2) (3.0.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.5.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->ohmeow-blurr==0.1.2) (2.0.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->ohmeow-blurr==0.1.2) (3.8.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets->ohmeow-blurr==0.1.2) (2021.11.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->ohmeow-blurr==0.1.2) (0.3.4)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->ohmeow-blurr==0.1.2) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->ohmeow-blurr==0.1.2) (0.70.12.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (4.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (5.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (2.0.8)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ohmeow-blurr==0.1.2) (21.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.2.5)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (7.6.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.2.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (5.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (3.5.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.12.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (0.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.4->ohmeow-blurr==0.1.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai>=2.4->ohmeow-blurr==0.1.2) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai>=2.4->ohmeow-blurr==0.1.2) (2018.9)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nbdev<2.0.0,>=1.1.0->ohmeow-blurr==0.1.2) (1.11.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score->ohmeow-blurr==0.1.2) (0.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score->ohmeow-blurr==0.1.2) (3.2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.6->ohmeow-blurr==0.1.2) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.6->ohmeow-blurr==0.1.2) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai>=2.4->ohmeow-blurr==0.1.2) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6OZq6RYcIHL"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6wERX9WYVqZ"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import *\n",
        "from fastai.text.all import *\n",
        "from blurr.data.all import *\n",
        "from blurr.modeling.all import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEc1KhC3cIHM"
      },
      "source": [
        "## Loading our snorkel training data\n",
        "\n",
        "We'll load the data we created previously using our labelling functions/snorkel. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxxpO7MdYb1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0eb196-bac4-4c55-a22a-6513f2550c6c"
      },
      "source": [
        "df = pd.read_csv(\"snorkel_train.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyZLkXh8cIHO"
      },
      "source": [
        "## Preparing our data \n",
        "\n",
        "Some of this will look fairly familiar from the previous but there is a little bit more 'housekeeping' to do now. We'll briefly explain what is happening in this different stages. \n",
        "\n",
        "First we create a variable which just stores the number of labels we could have. This is a bit redundant here since we know it's two but we might not always remember how many labels we have. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw-v5qoWZD-M",
        "outputId": "ef72fd56-3034-410d-d46a-b55ccee34ba2"
      },
      "source": [
        "n_labels = len(df[\"snorkel_genre\"].unique())\n",
        "n_labels"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3jEYZ2QcIHQ"
      },
      "source": [
        "We now need to specify the type of model we want to use. We want to do text classification, which is also known as 'sequence classification'. We use the Transformers libraries [`Auto Classes`](https://huggingface.co/transformers/model_doc/auto.html) to do a lot of the setup work of creating a model for the task we want to do (text classifcation) using a particular model architecture. This makes it very easy to swap the model we use without having to change our code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwk8EJynYU52"
      },
      "source": [
        "model_cls = AutoModelForSequenceClassification"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BfZK40DcIHQ"
      },
      "source": [
        "We now pass in the name of the model we want to use as our initial pre-trained model. We could choose from many of the models in the huggingface hub to serve as the starting point for our new transformer based model. In this case we choose 'distilbert-base-cased', this is a lighter version of Bert which is slightly less computationally expensive to train, we also use a 'cased' model. This means that \"Dog\" is different to \"dog\", since we have relatively short sequences of text and capitalisation is often important in a book title our intuition was that this model might work a little better than an uncased model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg51_TpYcIHQ"
      },
      "source": [
        "pretrained_model_name = \"distilbert-base-cased\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9ZHEL4wcIHR"
      },
      "source": [
        "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = n_labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6LsDZtqcIHR"
      },
      "source": [
        "We now use a blur method `get_hf_objects` to get all of the various components of our model (tokenizer, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnUJhEyScIHS"
      },
      "source": [
        "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
        "    pretrained_model_name, model_cls=model_cls, config=config\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goYf93LecIHU"
      },
      "source": [
        "We now load our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqZVw5AZeGu"
      },
      "source": [
        "blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock)\n",
        "dblock = DataBlock(\n",
        "    blocks=blocks,\n",
        "    get_x=ColReader(\"Title\"),\n",
        "    get_y=ColReader(\"snorkel_genre\"),\n",
        "    splitter=ColSplitter(),\n",
        ")\n",
        "dls = dblock.dataloaders(df, bs=16)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wN_wmZOcIHU"
      },
      "source": [
        "We can take a look at our data as we saw before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "LcrMQ1VIZir9",
        "outputId": "5edb3380-5003-49b0-a946-6e84174093b6"
      },
      "source": [
        "dls.show_batch(dataloaders=dls, max_n=2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Los HÃ©roes y las Maravillas del Mundo.... Anales del mundo desde los tiempos bÃ­blicos hasta nuestros dias.... Gran Memorandum histÃ³rico... que comprende Ã­ntegras las obras siguientes. La Imparcial... Historia Universal, escrita por el sabio Benedictino Clemente y su tan celebrado Arte de comprobar los datos de las fechas histÃ³ricas, crÃ³nicas y otros antiguos documentos ;... continuada hasta hoy dia por M. de Saint Allais ; la Historia de Alejandro el Grande, escrita por Quinto Curcio, la de CÃ¡rtago y Roma, Anibal y los Escipiones, Pompeyo y Cesar, continuados los famosos Comentarios de este Ãºltimo ; la de la guerra de Yugurta y Catilina, trasladado Ã­ntegro todo el Salustio. La Historia de la guerra de los Judios contra los Romanos.... Descripcion del Capitolio, destruccion de Jerusalen, Martirio de los Macabeos, etc. escrita por Flavio Josefo, traducida del original Griego... acompaÃ±adas dichas historias con las fideles tablas cronolÃ³gicas de la citada obra de Clemente.... Seguido todo de los tan celebrados cuadros de la pintura del hombre y de las maravillas que le rodean por... Buffon, Cuvier, Lacepede,... precedido del discurso sobre la Historia Universal por... Bossuet.... Dispuesto, ordenado, y completado el cuerpo general de la obra hasta el dia que termine por D. de Mora y Casarusa. Revisada la parte religiosa que comprende por I. Sayol y E</td>\n",
              "      <td>Non-fiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Les Corte - Real et leurs voyages au Nouveau - Monde, d'aprÃ¨s des documents nouveaux... tirÃ©s des archives de Lisbonne et de ModÃ¨ne. Suivi du texte inÃ©dit d'un rÃ©cit de la troisiÃ¨me expÃ©dition de Gaspar Corte - Real et d'une importante carte nautique portugaise de l'annÃ©e 1502 reproduite ici pour la premiÃ¨re fois. MÃ©moire lu Ã  l'AcadÃ©mie des inscriptions et belles - lettres, etc</td>\n",
              "      <td>Non-fiction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efoCbhD_cIHV"
      },
      "source": [
        "## Creating our learner \n",
        "\n",
        "We now create a fastai learner. This is a bit more verbose than previously because we specify an optimizer and don't use the `text_classifier_learner` convenience function but directly use a fastai `Learner` class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Po7IOPOZlFP"
      },
      "source": [
        "model = HF_BaseModelWrapper(hf_model)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SWhlAIqcIHW"
      },
      "source": [
        "learn = Learner(\n",
        "    dls,\n",
        "    model,\n",
        "    opt_func=partial(Adam, decouple_wd=True),\n",
        "    loss_func=CrossEntropyLossFlat(),\n",
        "    metrics=[F1Score(average=\"macro\")],\n",
        "    cbs=[HF_BaseModelCallback],\n",
        "    splitter=hf_splitter,\n",
        ").to_fp16()\n",
        "learn.unfreeze()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTaVfDZPcIHW"
      },
      "source": [
        "As we saw before we can use the learning rate finder to help find a suitable learning rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "83FAHS3LZoGn",
        "outputId": "5631c0a7-650f-4676-d870-69c9084be2fd"
      },
      "source": [
        "suggested = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnoG8RfQcIHW"
      },
      "source": [
        "## Training our model\n",
        "\n",
        "We are now ready to train our model. We again set a high number of epochs but as we did before we set a callback to stop training if we don't see any improvement. We are fairly 'aggressive' here with how long we accept for the model to not improve since transformers can take some time to converge and we might stop too early if we set our 'patience' value too low. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xjtkGNCXZo8w",
        "tags": [
          "hide-output"
        ],
        "outputId": "31edb691-dbfe-469a-f182-e119c4626ab6"
      },
      "source": [
        "learn.fit_one_cycle(\n",
        "    200,\n",
        "    lr_max=suggested.valley,\n",
        "    cbs=[\n",
        "        ShowGraphCallback(),\n",
        "        SaveModelCallback(monitor=\"f1_score\"),\n",
        "        EarlyStoppingCallback(monitor=\"f1_score\", patience=40),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.060123</td>\n",
              "      <td>0.051887</td>\n",
              "      <td>0.983149</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.039713</td>\n",
              "      <td>0.042197</td>\n",
              "      <td>0.985315</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.027020</td>\n",
              "      <td>0.041089</td>\n",
              "      <td>0.986084</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.029702</td>\n",
              "      <td>0.038905</td>\n",
              "      <td>0.988239</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.018178</td>\n",
              "      <td>0.049402</td>\n",
              "      <td>0.986665</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.009065</td>\n",
              "      <td>0.049319</td>\n",
              "      <td>0.988239</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.020446</td>\n",
              "      <td>0.060483</td>\n",
              "      <td>0.979554</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.002944</td>\n",
              "      <td>0.063162</td>\n",
              "      <td>0.987050</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.011935</td>\n",
              "      <td>0.062683</td>\n",
              "      <td>0.984502</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.004221</td>\n",
              "      <td>0.060780</td>\n",
              "      <td>0.986274</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.004522</td>\n",
              "      <td>0.062091</td>\n",
              "      <td>0.987845</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.007166</td>\n",
              "      <td>0.076208</td>\n",
              "      <td>0.986271</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.005970</td>\n",
              "      <td>0.079016</td>\n",
              "      <td>0.983505</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.003643</td>\n",
              "      <td>0.086152</td>\n",
              "      <td>0.987058</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.003472</td>\n",
              "      <td>0.067530</td>\n",
              "      <td>0.987650</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.004275</td>\n",
              "      <td>0.079636</td>\n",
              "      <td>0.984690</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>0.097226</td>\n",
              "      <td>0.987835</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.012736</td>\n",
              "      <td>0.105738</td>\n",
              "      <td>0.980152</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.009452</td>\n",
              "      <td>0.075489</td>\n",
              "      <td>0.987058</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.010471</td>\n",
              "      <td>0.075243</td>\n",
              "      <td>0.985091</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.004342</td>\n",
              "      <td>0.080865</td>\n",
              "      <td>0.987256</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.004818</td>\n",
              "      <td>0.065917</td>\n",
              "      <td>0.986469</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.003990</td>\n",
              "      <td>0.063894</td>\n",
              "      <td>0.989813</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.001782</td>\n",
              "      <td>0.068293</td>\n",
              "      <td>0.985486</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>0.087124</td>\n",
              "      <td>0.985504</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.001891</td>\n",
              "      <td>0.114441</td>\n",
              "      <td>0.981345</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>0.076350</td>\n",
              "      <td>0.986268</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.016404</td>\n",
              "      <td>0.064211</td>\n",
              "      <td>0.986668</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.007761</td>\n",
              "      <td>0.098833</td>\n",
              "      <td>0.981928</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.002238</td>\n",
              "      <td>0.086547</td>\n",
              "      <td>0.987844</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.001297</td>\n",
              "      <td>0.104954</td>\n",
              "      <td>0.986680</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.008544</td>\n",
              "      <td>0.090013</td>\n",
              "      <td>0.987068</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.021495</td>\n",
              "      <td>0.073693</td>\n",
              "      <td>0.986865</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.010735</td>\n",
              "      <td>0.076588</td>\n",
              "      <td>0.985287</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.019394</td>\n",
              "      <td>0.082637</td>\n",
              "      <td>0.985502</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.024986</td>\n",
              "      <td>0.095525</td>\n",
              "      <td>0.982754</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.007694</td>\n",
              "      <td>0.094301</td>\n",
              "      <td>0.983169</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>0.119983</td>\n",
              "      <td>0.977004</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.001733</td>\n",
              "      <td>0.106687</td>\n",
              "      <td>0.983328</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.009871</td>\n",
              "      <td>0.135160</td>\n",
              "      <td>0.983547</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.015142</td>\n",
              "      <td>0.100540</td>\n",
              "      <td>0.982729</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.001927</td>\n",
              "      <td>0.117343</td>\n",
              "      <td>0.986471</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.007925</td>\n",
              "      <td>0.117450</td>\n",
              "      <td>0.986677</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.008723</td>\n",
              "      <td>0.116880</td>\n",
              "      <td>0.982732</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.012559</td>\n",
              "      <td>0.094407</td>\n",
              "      <td>0.984513</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.016927</td>\n",
              "      <td>0.093906</td>\n",
              "      <td>0.984899</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.010378</td>\n",
              "      <td>0.104164</td>\n",
              "      <td>0.982724</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.014394</td>\n",
              "      <td>0.108287</td>\n",
              "      <td>0.981355</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.020906</td>\n",
              "      <td>0.081940</td>\n",
              "      <td>0.985282</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.003692</td>\n",
              "      <td>0.117217</td>\n",
              "      <td>0.981788</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.012168</td>\n",
              "      <td>0.094801</td>\n",
              "      <td>0.987057</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>0.139414</td>\n",
              "      <td>0.980965</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.003774</td>\n",
              "      <td>0.107085</td>\n",
              "      <td>0.984914</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.020428</td>\n",
              "      <td>0.109873</td>\n",
              "      <td>0.983160</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.004329</td>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.981409</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.018772</td>\n",
              "      <td>0.112568</td>\n",
              "      <td>0.981369</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.021617</td>\n",
              "      <td>0.104197</td>\n",
              "      <td>0.980429</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.002843</td>\n",
              "      <td>0.170612</td>\n",
              "      <td>0.980787</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.019212</td>\n",
              "      <td>0.085586</td>\n",
              "      <td>0.981965</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.004333</td>\n",
              "      <td>0.117783</td>\n",
              "      <td>0.984307</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.015321</td>\n",
              "      <td>0.098634</td>\n",
              "      <td>0.983136</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>0.129529</td>\n",
              "      <td>0.983737</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.002459</td>\n",
              "      <td>0.115576</td>\n",
              "      <td>0.976807</td>\n",
              "      <td>01:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better model found at epoch 0 with f1_score value: 0.9831487323424476.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better model found at epoch 1 with f1_score value: 0.9853153996035091.\n",
            "Better model found at epoch 2 with f1_score value: 0.9860838987594831.\n",
            "Better model found at epoch 3 with f1_score value: 0.9882387687911827.\n",
            "Better model found at epoch 22 with f1_score value: 0.9898127825545218.\n",
            "No improvement since epoch 22: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo4NeVCqJMT2",
        "outputId": "ca0ac6b9-9727-4326-c306-3a73382db5ef"
      },
      "source": [
        "learn.save(\"stage-1\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/stage-1.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZKIllY0cIHX"
      },
      "source": [
        "### Testing our model\n",
        "As before we want to see how our model does on unseen test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWOnbVoaRIEY"
      },
      "source": [
        "df_test = pd.read_csv(\"test_errors.csv\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZrCqoM_JRIA9",
        "outputId": "9cd4986c-c40f-4a8a-e1d2-fae253527676"
      },
      "source": [
        "df_test = df_test[[\"title\", \"true_label\"]]\n",
        "df_test = df_test.dropna(subset=[\"true_label\"]).copy()\n",
        "df_test = df_test[df_test.true_label.isin({\"non_fiction\", \"fiction\"})]\n",
        "test_data = learn.dls.test_dl(df_test.loc[:, \"title\"])\n",
        "preds = learn.get_preds(dl=test_data)\n",
        "probs = preds[0]\n",
        "predictions = probs.argmax(1)\n",
        "true_labels = df_test.true_label.astype(\"category\").cat.codes"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6htvdZiB2fs"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report, accuracy_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsWE2UUxXkP6",
        "outputId": "7fa9078a-74af-4fc4-93a1-449b984d4cd1"
      },
      "source": [
        "print(\n",
        "    classification_report(\n",
        "        true_labels,\n",
        "        predictions,\n",
        "    )\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.93       296\n",
            "           1       0.97      0.95      0.96       554\n",
            "\n",
            "    accuracy                           0.95       850\n",
            "   macro avg       0.94      0.95      0.94       850\n",
            "weighted avg       0.95      0.95      0.95       850\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x0MKl6FcIHZ"
      },
      "source": [
        "We can see that we do get some improvements compared to our previous model ðŸ¤—!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5WZyiBVRLbT"
      },
      "source": [
        "## Sharing our model (stage 1)\n",
        "\n",
        "We now have a model that is doing fairly well. Although we constructed this model for our particular task and data, it's still possible that others will benefit from this model so we might want to consider uploading it to the ðŸ¤— model hub. Let's start by poking around inside the `model` object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSxWp8le_g_J",
        "outputId": "2e8493a2-58d6-45cc-c12c-f500e74b0e4e"
      },
      "source": [
        "model.hf_model.config"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertConfig {\n",
              "  \"_name_or_path\": \"distilbert-base-cased\",\n",
              "  \"activation\": \"gelu\",\n",
              "  \"attention_dropout\": 0.1,\n",
              "  \"dim\": 768,\n",
              "  \"dropout\": 0.1,\n",
              "  \"hidden_dim\": 3072,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"distilbert\",\n",
              "  \"n_heads\": 12,\n",
              "  \"n_layers\": 6,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"qa_dropout\": 0.1,\n",
              "  \"seq_classif_dropout\": 0.2,\n",
              "  \"sinusoidal_pos_embds\": false,\n",
              "  \"tie_weights_\": true,\n",
              "  \"transformers_version\": \"4.12.5\",\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GCvc71DcIHZ"
      },
      "source": [
        "We can see that this includes a bunch of information about our model. One thing which we haven't got here is our labels. At the moment when we make predictions we get `0` or `1` back. To fix this we can quickly assign a dictionary to the `model.config` `id2label` attribute. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70OQTn97_qHN",
        "outputId": "da2890b3-2c80-415a-ba62-689e699f797c"
      },
      "source": [
        "dict(enumerate(dls.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'Fiction', 1: 'Non-fiction'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEMSuM6q_mEg"
      },
      "source": [
        "model.hf_model.config.id2label = dict(enumerate(dls.vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXHg7kvGVW-4"
      },
      "source": [
        "We can now upload to the hub. There are various ways in which we can do this, here we'll use the command line interface. First we login:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adt9j-2rZ-lq"
      },
      "source": [
        "!transformers-cli login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9f1-0GpcIHa"
      },
      "source": [
        "For Colab we also need to install [git lfs](https://git-lfs.github.com/). If you haven't come accross this before [git lfs](https://git-lfs.github.com/) is a tool for working with large files using Git. It can be very useful for versioning files, in this case our model, which are too big for GitHub to accept otherwise. In particular it can be very helpful in keeping track of versions of models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WM-FhSG8v-4",
        "tags": [
          "hide-output"
        ],
        "outputId": "dbdda0b4-8f87-4793-d1c1-9ea4d383f064"
      },
      "source": [
        "!sudo apt install git-lfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 1s (1,682 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 148492 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxXDGVNCcIHb"
      },
      "source": [
        "We initialize a git repo and install git lfs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH8cldjH8z3c",
        "tags": [
          "hide-output"
        ],
        "outputId": "85130a35-ce6d-4b7a-c3ca-e9c24c474ed0"
      },
      "source": [
        "!git init\n",
        "!git lfs install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcANqQuYcIHb"
      },
      "source": [
        "We also put in some basic data for Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvYl7YOo9RDh",
        "tags": [
          "hide-output"
        ]
      },
      "source": [
        "!git config --global user.email EMAIL\n",
        "!git config --global user.name NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_e3PiOacIHc"
      },
      "source": [
        "## Push to the ðŸ¤— hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "74511a0880dc42259be42c9898acba62",
            "d805ea32d4cd4526971ff71e056ea12f",
            "24a2b05e0fe44fdcbeabe0a3acf1ae04",
            "c0e532e7f5a34905855f90fd03cf8e62",
            "6721a3c037374d42a9c1e22477193686",
            "8f19c9c084e74f45bc9da3a1c5e29709",
            "186181040cf4404897f1fb75308a04e1",
            "e1e30ae819d64d54a7cab7d0f5d5368f",
            "0323875ac1374172a97ed1d6f36b27bc",
            "dddc7979cdf345998c4e93f884ff71a9",
            "f92d1e141780416dacc3c8777d2e922b"
          ]
        },
        "id": "Nxo8tx5E4rpH",
        "outputId": "3fa60e6a-9607-4a5a-9bba-4e498a421ac2"
      },
      "source": [
        "model.hf_model.push_to_hub(\"bl-books-genre\", private=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning https://huggingface.co/davanstrien/bl-books-genre into local empty directory.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74511a0880dc42259be42c9898acba62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 3.45k/251M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "To https://huggingface.co/davanstrien/bl-books-genre\n",
            "   784ae4b..b063856  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/davanstrien/bl-books-genre/commit/b0638563b8155fa1699beda323a0a3cfbccf4731'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_BuLDP18h0O"
      },
      "source": [
        "hf_tokenizer.push_to_hub(\"bl-books-genre\", private=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF8BThXucIHe"
      },
      "source": [
        "For now we keep our model 'private', in a subsequent section we'll look at a few things which we probably want to do before we unleash our model into the wild. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMPMfeAmcIHe"
      },
      "source": [
        "``````{note}\n",
        "In this notebook we finally got to play with a transformer model, and we do benefit from slightly improved performance. However, much of this performance came from having built a better training set, and having already built a model and begun to understand the errors of this model. We originally trained a transformer model (an even bigger one) on this data and got worse results than in our fastai model. It is almost always worth a bit of effort improving our data rather than reaching straight for the biggest model we can fit on our GPU.\n",
        "```\n"
      ]
    }
  ]
}
