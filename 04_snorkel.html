
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Creating More Training Data Without More Annotating &#8212; Classifying 19th Century British Library books using Crowdsourcing and Machine Learning</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using our newly expanded data" href="04_using_our_new_data.html" />
    <link rel="prev" title="Assessing Where our Model is Going Wrong" href="02_error_analysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Classifying 19th Century British Library books using Crowdsourcing and Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Genre Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="zooniverse.html">
   Overview of the Project: Classifying British Library Books By Genre
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="genre_classification.html">
   Genre Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="00_crude_genre.html">
   Crude Genre Classification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Exploratory Data Analysis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="sample_inspector_i.html">
   Sample Inspector (Part I)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sample_inspector_ii.html">
   Sample Inspector (Part II)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Training our first model
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_BL_fiction_non_fiction.html">
   Training our first book genre classification model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="01b_inference.html">
   Model inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assesing our models performance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01b_improving_results.html">
   Improving our model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_error_analysis.html">
   Assessing Where our Model is Going Wrong
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Improving our model
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Creating More Training Data Without More Annotating
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_using_our_new_data.html">
   Using our newly expanded data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04a_fastai.html">
   Fine tuning our fastai model with new data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04b_transformer.html">
   Using a Transformer Based Model
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sharing our results and final inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="05_share_outputs.html">
   Sharing our work
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_pipeline_inference.html">
   Using our new Hugging Face model
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Further resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="other_resources.html">
   Other resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="references.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="glossary.html">
   Glossary
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/04_snorkel.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Living-with-machines/genre-classification"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Living-with-machines/genre-classification/issues/new?title=Issue%20on%20page%20%2F04_snorkel.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Living-with-machines/genre-classification/main?urlpath=tree/genre_classification_of_bl_books/04_snorkel.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/Living-with-machines/genre-classification/blob/main/genre_classification_of_bl_books/04_snorkel.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#combining-domain-expertise-and-machine-learning">
   Combining Domain Expertise and Machine Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#programmatically-generating-training-data">
   Programmatically Generating Training Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generating-new-genre-training-data">
     Generating New Genre Training Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-a-labeling-function">
   What is a labeling function?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-makes-a-good-labelling-function">
   What Makes a Good Labelling Function?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#important-words">
     Important Words?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-our-labelling-functions">
   Creating our Labelling Functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#heuristics">
   Heuristics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision-vs-recall-what-value-to-use-for-our-threshold">
     Precision vs Recall: What Value to use for our Threshold?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#add-keywords">
     Add Keywords
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#leveraging-other-models">
   Leveraging Other Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-named-entities-for-labeling-functions">
     Using named entities for labeling functions.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-our-previous-model">
   Using our previous model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-more-training-data">
   Creating more training data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-our-new-training-data">
   Creating our new training data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#map-to-our-original-labels">
     Map to our original labels
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#selecting-required-columns">
     Selecting required columns
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prioritising-human-annotations">
     Prioritising human annotations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-leakage">
   Data leakage
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#removing-data-which-is-in-our-test-data">
     Removing data which is in our test data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-new-splits">
     Creating new splits
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#saving-our-new-training-data">
   Saving our new training data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#next-steps">
   Next steps
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="creating-more-training-data-without-more-annotating">
<h1>Creating More Training Data Without More Annotating<a class="headerlink" href="#creating-more-training-data-without-more-annotating" title="Permalink to this headline">¶</a></h1>
<p>We previously listed ‘annotating’ more data as one way of improving our model. Since supervised learning requires data, having more data <em>may</em> be <em>potentially</em> helpful for improving our model.</p>
<p>One obvious downside of this is that collecting more training data is time consuming and may not always be very practical. In a GLAM setting we may want to use machine learning to do a task which we wouldn’t otherwise have time to do. If we have to spend a lot of time creating our training data, the machine learning approach may also become impractical in terms of resources.</p>
<div class="section" id="combining-domain-expertise-and-machine-learning">
<h2>Combining Domain Expertise and Machine Learning<a class="headerlink" href="#combining-domain-expertise-and-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>The time taken to create training data is one weakness of machine learning for practical tasks. Another potential frustration domain experts may have is that their knowledge isn’t always incorporated into the machine learning process. For our use case of trying to identify the genre of a book we may already have a sense of some possible ways in which we could identify whether a book was fiction or non-fiction. For example we may already know that titles for non-fiction books tend to be longer than fiction book titles (cf. ‘An account of the mining villages of Wales’ vs ‘Oliver Twist’). If we create our training data in the usual way by labeling examples of our data with the correct label we might not be able to incorporate this domain knowledge very easily. This might be okay in some cases but we might be able to save time and get better results by trying to leverage what we already know (or can access via domain experts).</p>
</div>
<div class="section" id="programmatically-generating-training-data">
<h2>Programmatically Generating Training Data<a class="headerlink" href="#programmatically-generating-training-data" title="Permalink to this headline">¶</a></h2>
<p>One way in which we could do this is by writing a <code class="docutils literal notranslate"><span class="pre">labelling</span> <span class="pre">function</span></code> to label titles as being either fiction or non-fiction based on the length of the title - i.e. without any annotation by hand. However, a weakness of this approach is that it deals with averages which might not always be correct. Some non-fiction book titles will be shorter than our threshold, and vice-versa for fiction books. If we could simply determine genre based on the average length of titles, we could have skipped this whole machine learning process and be done already.</p>
<p>So our problem is that we have some sense of functions we could use to label our data, but these functions are likely to be wrong some of the time. In this notebook we’ll explore how we can use a Python library <code class="docutils literal notranslate"><span class="pre">Snorkel</span></code> to deal with this challenge and try and create additional annotations without doing any annotating by hand.</p>
<div class="section" id="generating-new-genre-training-data">
<h3>Generating New Genre Training Data<a class="headerlink" href="#generating-new-genre-training-data" title="Permalink to this headline">¶</a></h3>
<p>How will we try to approach this in our particular situation? As a reminder of our broad task, we have a collection of metadata related to the Microsoft Digitised Books collection. The ‘genre’ field isn’t yet fully populated. We have previously used a subset of this data to train a machine learning model.</p>
<p>What we want to do is to try and write some labelling functions that will add more labels to the full metadata dataset, so that we can give our models more examples to learn from. If we are able to do this we’ll hopefully be able to improve the performance of our model from our previous attempts.</p>
<p>We’ll start by doing some installation of our libraries we’ll be using in this notebook.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install snorkel
<span class="o">!</span>pip install fastai --upgrade
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: snorkel in /usr/local/lib/python3.7/dist-packages (0.9.7)
Requirement already satisfied: torch&lt;2.0.0,&gt;=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.9.0+cu111)
Requirement already satisfied: scipy&lt;2.0.0,&gt;=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.4.1)
Requirement already satisfied: munkres&gt;=1.0.6 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.4)
Requirement already satisfied: numpy&lt;1.20.0,&gt;=1.16.5 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.19.5)
Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.62.3)
Requirement already satisfied: scikit-learn&lt;0.25.0,&gt;=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (0.22.2.post1)
Requirement already satisfied: networkx&lt;2.4,&gt;=2.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.3)
Requirement already satisfied: pandas&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.5)
Requirement already satisfied: tensorboard&lt;2.0.0,&gt;=1.14.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.15.0)
Requirement already satisfied: decorator&gt;=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx&lt;2.4,&gt;=2.2-&gt;snorkel) (4.4.2)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas&lt;2.0.0,&gt;=1.0.0-&gt;snorkel) (2018.9)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&lt;2.0.0,&gt;=1.0.0-&gt;snorkel) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&lt;2.0.0,&gt;=1.0.0-&gt;snorkel) (1.15.0)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.25.0,&gt;=0.20.2-&gt;snorkel) (1.1.0)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (1.0.1)
Requirement already satisfied: grpcio&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (1.41.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (57.4.0)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (0.12.0)
Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (3.17.3)
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (0.37.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (3.3.4)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (4.8.1)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch&lt;2.0.0,&gt;=1.2.0-&gt;snorkel) (3.10.0.2)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;markdown&gt;=2.6.8-&gt;tensorboard&lt;2.0.0,&gt;=1.14.0-&gt;snorkel) (3.6.0)
Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.5.3)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.2)
Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)
Requirement already satisfied: torchvision&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu111)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)
Requirement already satisfied: fastcore&lt;1.4,&gt;=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.27)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)
Requirement already satisfied: pillow&gt;6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)
Requirement already satisfied: torch&lt;1.11,&gt;=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu111)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)
Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)
Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.5)
Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)
Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress&gt;=0.2.4-&gt;fastai) (1.19.5)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (2.0.6)
Requirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.5)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (3.0.6)
Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.1.3)
Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.0)
Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (7.4.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (57.4.0)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (1.0.6)
Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (4.62.3)
Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (0.4.1)
Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&lt;4-&gt;fastai) (0.8.2)
Requirement already satisfied: importlib-metadata&gt;=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai) (4.8.1)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai) (3.6.0)
Requirement already satisfied: typing-extensions&gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;4-&gt;fastai) (3.10.0.2)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (2021.10.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;fastai) (3.0.4)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai) (2.8.2)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai) (2.4.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai) (0.11.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;fastai) (1.3.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;fastai) (1.15.0)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;fastai) (2018.9)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;fastai) (1.1.0)
</pre></div>
</div>
</div>
</div>
<p>Since we already have some training data we can leverage this to help us develop <code class="docutils literal notranslate"><span class="pre">labelling</span> <span class="pre">functions</span></code> (more on this below) and to test how well these work.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtypes</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;BL record ID&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Type of resource&quot;</span><span class="p">:</span> <span class="s2">&quot;category&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Name&quot;</span><span class="p">:</span> <span class="s2">&quot;category&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Type of name&quot;</span><span class="p">:</span> <span class="s2">&quot;category&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Country of publication&quot;</span><span class="p">:</span> <span class="s2">&quot;category&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Place of publication&quot;</span><span class="p">:</span> <span class="s2">&quot;category&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Genre&quot;</span><span class="p">:</span> <span class="s2">&quot;category&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Dewey classification&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
    <span class="s2">&quot;BL record ID for physical resource&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
    <span class="s2">&quot;annotator_main_language&quot;</span><span class="p">:</span> <span class="s2">&quot;category&quot;</span><span class="p">,</span>
    <span class="s2">&quot;annotator_summaries_language&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>\ #TODO update link when repository public</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;train_valid.csv&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BL record ID</th>
      <th>Type of resource</th>
      <th>Name</th>
      <th>Dates associated with name</th>
      <th>Type of name</th>
      <th>Role</th>
      <th>All names</th>
      <th>Title</th>
      <th>Variant titles</th>
      <th>Series title</th>
      <th>Number within series</th>
      <th>Country of publication</th>
      <th>Place of publication</th>
      <th>Publisher</th>
      <th>Date of publication</th>
      <th>Edition</th>
      <th>Physical description</th>
      <th>Dewey classification</th>
      <th>BL shelfmark</th>
      <th>Topics</th>
      <th>Genre</th>
      <th>Languages</th>
      <th>Notes</th>
      <th>BL record ID for physical resource</th>
      <th>classification_id</th>
      <th>user_id</th>
      <th>created_at</th>
      <th>subject_ids</th>
      <th>annotator_date_pub</th>
      <th>annotator_normalised_date_pub</th>
      <th>annotator_edition_statement</th>
      <th>annotator_genre</th>
      <th>annotator_FAST_genre_terms</th>
      <th>annotator_FAST_subject_terms</th>
      <th>annotator_comments</th>
      <th>annotator_main_language</th>
      <th>annotator_other_languages_summaries</th>
      <th>annotator_summaries_language</th>
      <th>annotator_translation</th>
      <th>annotator_original_language</th>
      <th>annotator_publisher</th>
      <th>annotator_place_pub</th>
      <th>annotator_country</th>
      <th>annotator_title</th>
      <th>Link to digitised book</th>
      <th>annotated</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>014616539</td>
      <td>Monograph</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Hazlitt, William Carew, 1834-1913 [person]</td>
      <td>The Baron's Daughter. A ballad by the author o...</td>
      <td>Single Works</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Scotland</td>
      <td>Edinburgh</td>
      <td>Ballantyne, Hanson</td>
      <td>1877</td>
      <td>NaN</td>
      <td>20 pages (4°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 11651.h.6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000206670</td>
      <td>263940444.0</td>
      <td>3.0</td>
      <td>2020-07-27 07:35:13 UTC</td>
      <td>44330917.0</td>
      <td>1877</td>
      <td>1877</td>
      <td>NONE</td>
      <td>Fiction</td>
      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>
      <td>NONE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>&lt;NA&gt;</td>
      <td>No</td>
      <td>NaN</td>
      <td>Ballantyne Hanson &amp; Co.</td>
      <td>Edinburgh</td>
      <td>stk</td>
      <td>The Baron's Daughter. A ballad by the author o...</td>
      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc...</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We’ll use only the data from the training split so we’re can continue to use the validation split to compare our results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">is_valid</span> <span class="o">==</span> <span class="kc">False</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Check how many examples we have to work with</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3262
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="what-is-a-labeling-function">
<h2>What is a labeling function?<a class="headerlink" href="#what-is-a-labeling-function" title="Permalink to this headline">¶</a></h2>
<p>We briefly described a function we could use to label our data using the length of the title. When we use a programmatic approach to creating our training data we can refer to the functions which we use to create our labels as <code class="docutils literal notranslate"><span class="pre">labeling</span> <span class="pre">function</span></code>. We’ll follow a lot of the approaches outlined in the Snorkel <a class="reference external" href="https://www.snorkel.org/use-cases/01-spam-tutorial">tutorial</a> in this notebook. They provide this example of a labeling function for the task of identifying if a youtube comment is spam or not:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.labeling</span> <span class="kn">import</span> <span class="n">labeling_function</span>


<span class="nd">@labeling_function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">lf_contains_link</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># Return a label of SPAM if &quot;http&quot; in comment text, otherwise ABSTAIN</span>
    <span class="k">return</span> <span class="n">SPAM</span> <span class="k">if</span> <span class="s2">&quot;http&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">else</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>There are a few things to note here, but, since we’re following a lot of what is covered in the Snorkel tutorial we won’t repeat things in too much detail.</p>
<p>The first thing we need is to import <code class="docutils literal notranslate"><span class="pre">labeling_function</span></code> from <code class="docutils literal notranslate"><span class="pre">snorkel</span></code> as we use this for declaring our labeling functions. The way in which we create a labeling function will depend on our data, and how we might label it, but in this example we have a simple python function which returns <code class="docutils literal notranslate"><span class="pre">SPAM</span></code> if the text <code class="docutils literal notranslate"><span class="pre">http</span></code> appears in the comment text, if it doesn’t it returns <code class="docutils literal notranslate"><span class="pre">ABSTAIN</span></code>.</p>
<p>We use a python decorator to indicate that this is a labeling function. If you aren’t familiar with Python decorators should just remember that decorators are used to modify the behavior of a function (the one it decorates), just as fairy lights decorate a Christmas tree  and change its behaviour from ‘tree’ to ‘festive ornament’. This will make more sense in the context of Snorkel later on.</p>
<p>If you want to dig into decorators further this <a class="reference external" href="https://realpython.com/primer-on-python-decorators/">article</a> on <a class="reference external" href="https://realpython.com/">Real Python</a> provides a nice introduction, or, if prefer to watch a video this <a class="reference external" href="https://youtu.be/FsAPt_9Bf3U">youtube tutorial</a> gives a nice overview too.</p>
<p>We can see here that the labeling function makes use of the idea that people often include links in spam comments i.e. “plz checkout my etsy store at http:….”. Obviously this won’t be correct all the time but fortunately Snorkel has some ways to deal with this.</p>
</div>
<div class="section" id="what-makes-a-good-labelling-function">
<h2>What Makes a Good Labelling Function?<a class="headerlink" href="#what-makes-a-good-labelling-function" title="Permalink to this headline">¶</a></h2>
<p>One question we might already have is “what makes a good labeling function?”. The short, annoying, answer is that it depends on context. We often have intutions about things that might work because we know the domain or have picked up ideas from working with some of the data already. In our particular example of distinguishing fiction from non-fiction books we may think that some words are likely to indicate whether a book is fiction or non-fiction. We’ll start by exploring this.</p>
<div class="section" id="important-words">
<h3>Important Words?<a class="headerlink" href="#important-words" title="Permalink to this headline">¶</a></h3>
<p>A fairly naive approach to trying to labeling a title as ‘fiction’ or ‘non-fiction’ would be to use some keywords. Let’s start by finding the most common 50 words. We can use the <code class="docutils literal notranslate"><span class="pre">Counter</span></code> class from the delightful <a class="reference external" href="https://docs.python.org/3.3/library/collections.html#module-collections"><code class="docutils literal notranslate"><span class="pre">collections</span></code></a> module to do this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Counter</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;Title&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">split</span><span class="p">())</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;of&#39;, 2255),
 (&#39;the&#39;, 1785),
 (&#39;and&#39;, 1536),
 (&#39;...&#39;, 1054),
 (&#39;in&#39;, 819),
 (&#39;The&#39;, 693),
 (&#39;A&#39;, 625),
 (&#39;a&#39;, 625),
 (&#39;etc&#39;, 557),
 (&#39;by&#39;, 472),
 (&#39;to&#39;, 413),
 (&#39;With&#39;, 314),
 (&#39;from&#39;, 268),
 (&#39;with&#39;, 250),
 (&#39;de&#39;, 228),
 (&#39;van&#39;, 223),
 (&#39;By&#39;, 201),
 (&#39;its&#39;, 196),
 (&#39;en&#39;, 194),
 (&#39;der&#39;, 193),
 (&#39;History&#39;, 179),
 (&#39;J.&#39;, 159),
 (&#39;on&#39;, 158),
 (&#39;an&#39;, 157),
 (&#39;[With&#39;, 157),
 (&#39;[A&#39;, 152),
 (&#39;illustrations&#39;, 152),
 (&#39;New&#39;, 125),
 (&#39;other&#39;, 121),
 (&#39;for&#39;, 117),
 (&#39;novel.]&#39;, 111),
 (&#39;edition&#39;, 110),
 (&#39;or,&#39;, 109),
 (&#39;H.&#39;, 108),
 (&#39;Illustrated&#39;, 98),
 (&#39;A.&#39;, 96),
 (&#39;und&#39;, 91),
 (&#39;af&#39;, 88),
 (&#39;G.&#39;, 87),
 (&#39;den&#39;, 87),
 (&#39;och&#39;, 75),
 (&#39;C.&#39;, 73),
 (&#39;or&#39;, 72),
 (&#39;i&#39;, 71),
 (&#39;het&#39;, 70),
 (&#39;An&#39;, 68),
 (&#39;Edited&#39;, 67),
 (&#39;novel&#39;, 67),
 (&#39;W.&#39;, 64),
 (&#39;during&#39;, 64)]
</pre></div>
</div>
</div>
</div>
<p>We can see here that the most common words tend to be <a class="reference external" href="https://en.wikipedia.org/wiki/Stop_word">stop words</a>. Since we want to know which words might be unique to fiction <em>or</em> non-fiction we’ll look at each of these separately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_fiction</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;annotator_genre&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Fiction&quot;</span><span class="p">]</span>
<span class="n">df_non_fiction</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;annotator_genre&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Non-fiction&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">most_frequent_fiction</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_fiction</span><span class="p">[</span><span class="s2">&quot;Title&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">split</span><span class="p">())</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">most_frequent_fiction</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;of&#39;, 490),
 (&#39;The&#39;, 331),
 (&#39;A&#39;, 316),
 (&#39;the&#39;, 260),
 (&#39;and&#39;, 242),
 (&#39;a&#39;, 184),
 (&#39;...&#39;, 177),
 (&#39;[A&#39;, 147),
 (&#39;by&#39;, 138),
 (&#39;in&#39;, 112),
 (&#39;novel.]&#39;, 111),
 (&#39;etc&#39;, 104),
 (&#39;By&#39;, 104),
 (&#39;other&#39;, 94),
 (&#39;novel&#39;, 67),
 (&#39;With&#39;, 53),
 (&#39;tale&#39;, 50),
 (&#39;der&#39;, 49),
 (&#39;edition&#39;, 48),
 (&#39;de&#39;, 47),
 (&#39;author&#39;, 45),
 (&#39;van&#39;, 45),
 (&#39;or,&#39;, 41),
 (&#39;en&#39;, 40),
 (&#39;Poems&#39;, 39),
 (&#39;J.&#39;, 39),
 (&#39;story&#39;, 39),
 (&#39;illustrations&#39;, 38),
 (&#39;[i.e.&#39;, 35),
 (&#39;A.&#39;, 34),
 (&#39;stories&#39;, 30),
 (&#39;romance&#39;, 29),
 (&#39;H.&#39;, 28),
 (&#39;poems&#39;, 28),
 (&#39;or&#39;, 26),
 (&#39;Second&#39;, 26),
 (&#39;und&#39;, 26),
 (&#39;C.&#39;, 25),
 (&#39;poem&#39;, 25),
 (&#39;with&#39;, 25),
 (&#39;verse&#39;, 24),
 (&#39;An&#39;, 24),
 (&#39;from&#39;, 24),
 (&#39;Tales&#39;, 24),
 (&#39;New&#39;, 23),
 (&#39;for&#39;, 20),
 (&#39;acts&#39;, 20),
 (&#39;collection&#39;, 20),
 (&#39;het&#39;, 20),
 (&#39;an&#39;, 19)]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">most_frequent_non_fiction</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span>
    <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_non_fiction</span><span class="p">[</span><span class="s2">&quot;Title&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">most_frequent_non_fiction</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;of&#39;, 1765),
 (&#39;the&#39;, 1525),
 (&#39;and&#39;, 1294),
 (&#39;...&#39;, 877),
 (&#39;in&#39;, 707),
 (&#39;etc&#39;, 453),
 (&#39;a&#39;, 441),
 (&#39;to&#39;, 397),
 (&#39;The&#39;, 362),
 (&#39;by&#39;, 334),
 (&#39;A&#39;, 309),
 (&#39;With&#39;, 261),
 (&#39;from&#39;, 244),
 (&#39;with&#39;, 225),
 (&#39;its&#39;, 193),
 (&#39;de&#39;, 181),
 (&#39;van&#39;, 178),
 (&#39;History&#39;, 176),
 (&#39;en&#39;, 154),
 (&#39;on&#39;, 153),
 (&#39;[With&#39;, 144),
 (&#39;der&#39;, 144),
 (&#39;an&#39;, 138),
 (&#39;J.&#39;, 120),
 (&#39;illustrations&#39;, 114),
 (&#39;New&#39;, 102),
 (&#39;for&#39;, 97),
 (&#39;By&#39;, 97),
 (&#39;Illustrated&#39;, 94),
 (&#39;af&#39;, 88),
 (&#39;H.&#39;, 80),
 (&#39;och&#39;, 75),
 (&#39;den&#39;, 75),
 (&#39;G.&#39;, 74),
 (&#39;i&#39;, 71),
 (&#39;or,&#39;, 68),
 (&#39;und&#39;, 65),
 (&#39;during&#39;, 64),
 (&#39;edition&#39;, 62),
 (&#39;A.&#39;, 62),
 (&#39;history&#39;, 62),
 (&#39;og&#39;, 61),
 (&#39;account&#39;, 57),
 (&#39;sketches&#39;, 54),
 (&#39;W.&#39;, 53),
 (&#39;P.&#39;, 51),
 (&#39;through&#39;, 51),
 (&#39;notes&#39;, 50),
 (&#39;edition,&#39;, 50),
 (&#39;het&#39;, 50)]
</pre></div>
</div>
</div>
</div>
<p>For our indicator words to be most reliable we would rather they didn’t appear frequently in both fiction and non-fiction titles. We can use a set to check the values which aren’t in both fiction and non-fiction titles.</p>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">set</span><span class="p">(</span><span class="n">most_frequent_non_fiction</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">most_frequent_fiction</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{(&#39;...&#39;, 877),
 (&#39;A&#39;, 309),
 (&#39;A.&#39;, 62),
 (&#39;By&#39;, 97),
 (&#39;G.&#39;, 74),
 (&#39;H.&#39;, 80),
 (&#39;History&#39;, 176),
 (&#39;Illustrated&#39;, 94),
 (&#39;J.&#39;, 120),
 (&#39;New&#39;, 102),
 (&#39;P.&#39;, 51),
 (&#39;The&#39;, 362),
 (&#39;W.&#39;, 53),
 (&#39;With&#39;, 261),
 (&#39;[With&#39;, 144),
 (&#39;a&#39;, 441),
 (&#39;account&#39;, 57),
 (&#39;af&#39;, 88),
 (&#39;an&#39;, 138),
 (&#39;and&#39;, 1294),
 (&#39;by&#39;, 334),
 (&#39;de&#39;, 181),
 (&#39;den&#39;, 75),
 (&#39;der&#39;, 144),
 (&#39;during&#39;, 64),
 (&#39;edition&#39;, 62),
 (&#39;edition,&#39;, 50),
 (&#39;en&#39;, 154),
 (&#39;etc&#39;, 453),
 (&#39;for&#39;, 97),
 (&#39;from&#39;, 244),
 (&#39;het&#39;, 50),
 (&#39;history&#39;, 62),
 (&#39;i&#39;, 71),
 (&#39;illustrations&#39;, 114),
 (&#39;in&#39;, 707),
 (&#39;its&#39;, 193),
 (&#39;notes&#39;, 50),
 (&#39;och&#39;, 75),
 (&#39;of&#39;, 1765),
 (&#39;og&#39;, 61),
 (&#39;on&#39;, 153),
 (&#39;or,&#39;, 68),
 (&#39;sketches&#39;, 54),
 (&#39;the&#39;, 1525),
 (&#39;through&#39;, 51),
 (&#39;to&#39;, 397),
 (&#39;und&#39;, 65),
 (&#39;van&#39;, 178),
 (&#39;with&#39;, 225)}
</pre></div>
</div>
</div>
</div>
<p>These words are still fairly noisy so we might be wary of using many of them. There are some which make sense intuitively so we’ll try some of these out and see how they perform.</p>
</div>
</div>
<div class="section" id="creating-our-labelling-functions">
<h2>Creating our Labelling Functions<a class="headerlink" href="#creating-our-labelling-functions" title="Permalink to this headline">¶</a></h2>
<p>We’ll start by setting some constants for our labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ABSTAIN</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">FICTION</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">NON_FICTION</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>It is important to note that we set an option for <code class="docutils literal notranslate"><span class="pre">ABSTAIN</span></code>. We often want to add an option to our labeling functions that defers from making a prediction. We usually write our labeling function to try and indicate a label, but usually if the function isn’t satisfied doesn’t indicate that the other label is correct.</p>
<p>Another important part of labeling functions is that we usually want to have many labeling functions, and, since we’re not relying on a single function to label our data it’s often better for our labeling function to return <code class="docutils literal notranslate"><span class="pre">ABSTAIN</span></code> if our labeling condition isn’t met rather than returning another label. This becomes even more important if we have multiple labels.</p>
<p>One function we could try to start with is checking if the word “Novel” appears in the title text. You may have noticed that in this particular dataset the word novel often appears as part of the title so this <em>could</em> be a useful indicator of fiction titles.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>We want to be careful that our labeling functions are specific to our data. In the BL books title metadata that we’re trying to label we have noticed that things like <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">Novel</span> <span class="pre">by...</span></code> appear in the title. This may not be the case for other book titles in different catalogues.</p>
</div>
<p>Our first labeling function is basically the same as the spam example above except we look for the word “novel”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">lf_contains_novel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">FICTION</span> <span class="k">if</span> <span class="s2">&quot;novel&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">Title</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">else</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>Now we have our labeling function we can apply it to our data. We’ll start by doing this only with our validation data since we have the correct labels for this to compare our functions against.</p>
<p>There are various ways in which Snorkel can apply our functions to our data. In this notebook we’ll stick with an approach designed to work with Pandas dataframes. If we have a larger amount of data to label we might want to explore the use of <a class="reference external" href="https://snorkel.readthedocs.io/en/v0.9.6/packages/_autosummary/labeling/snorkel.labeling.apply.dask.DaskLFApplier.html">dask applifer functions</a>. This uses the <a class="reference external" href="https://dask.org/">dask</a> library to scale the appliation of labelling functions to very large datasets. We won’t need this here but if you are planning to develop this approach with very large collections this could be worth exploring.</p>
<p>We put our labelling functions in a list called <code class="docutils literal notranslate"><span class="pre">LFS</span></code>, we then create an applier object and pass in our dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.labeling</span> <span class="kn">import</span> <span class="n">PandasLFApplier</span>

<span class="n">lfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">lf_contains_novel</span><span class="p">]</span>

<span class="n">applier</span> <span class="o">=</span> <span class="n">PandasLFApplier</span><span class="p">(</span><span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span>
<span class="n">L_train</span> <span class="o">=</span> <span class="n">applier</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 3262/3262 [00:00&lt;00:00, 39484.97it/s]
</pre></div>
</div>
</div>
</div>
<p>We store the output of this in a new variable <code class="docutils literal notranslate"><span class="pre">L_train</span></code>. We can use <code class="docutils literal notranslate"><span class="pre">LFAnalysis</span></code> to get a summary of what our current labeling function is doing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.labeling</span> <span class="kn">import</span> <span class="n">LFAnalysis</span>

<span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>j</th>
      <th>Polarity</th>
      <th>Coverage</th>
      <th>Overlaps</th>
      <th>Conflicts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lf_contains_novel</th>
      <td>0</td>
      <td>[0]</td>
      <td>0.058553</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see a row for our current labeling function, we can also see that at the moment our coverage (i.e. how much of our data is labeled by our function) is very low. At the moment we don’t have any overlaps or conflicts since these are relevant only when we have multiple labeling functions.</p>
<p>We have ground truth labels that we can use to evaluate how accurate our labeling function is. To to his we need to use the same labels as Snorkel for ground truth so we’ll map our labels to the constants we made above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">annotator_genre</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s2">&quot;Fiction&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Non-fiction&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>We can pass our ground truth labels to <code class="docutils literal notranslate"><span class="pre">lf_empirical_accuracies</span></code> to get a sumaary of the peformance of our functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_empirical_accuracies</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.])
</pre></div>
</div>
</div>
</div>
<p>We can see here that our current function is 100% accurate. We shouldn’t get too excited about this since our coverage is very low. We’ll need to write some more labeling functions to make sure that we have some chance of labeling more of our data than we currently have done.</p>
</div>
<div class="section" id="heuristics">
<h2>Heuristics<a class="headerlink" href="#heuristics" title="Permalink to this headline">¶</a></h2>
<p>We could also use heuristics for our labeling functions. For example the length of the title. I don’t have any idea what threshold to use for this. Since we have some labels we can try and identify a sensible threshold. First we’ll add a new columns to our DataFrame which contains the length of our titles.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;text_len&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Title&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We’ll now use a pandas <code class="docutils literal notranslate"><span class="pre">groupby</span></code> to see what the lengths look like for fiction vs non-fiction books. Since it might be useful to have a sense of the distributions we’ll use <code class="docutils literal notranslate"><span class="pre">describe</span></code> instead of mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;annotator_genre&quot;</span><span class="p">])[</span><span class="s2">&quot;text_len&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>annotator_genre</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Fiction</th>
      <td>1083.0</td>
      <td>49.438596</td>
      <td>35.095600</td>
      <td>5.0</td>
      <td>25.0</td>
      <td>39.0</td>
      <td>63.0</td>
      <td>271.0</td>
    </tr>
    <tr>
      <th>Non-fiction</th>
      <td>2179.0</td>
      <td>92.317118</td>
      <td>58.458339</td>
      <td>8.0</td>
      <td>50.0</td>
      <td>78.0</td>
      <td>125.0</td>
      <td>469.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="section" id="precision-vs-recall-what-value-to-use-for-our-threshold">
<h3>Precision vs Recall: What Value to use for our Threshold?<a class="headerlink" href="#precision-vs-recall-what-value-to-use-for-our-threshold" title="Permalink to this headline">¶</a></h3>
<p>We can see various values for mean, min etc. What would be a reasonable value to use for our threshold for a labeling function which labeled a title as ‘non-fiction’? This partly comes down to whether we want high coverage (or recall) or high precision. If we choose a threshold that is higher we will label fewer examples, but they will be more likely to be correct.</p>
<p>For example, if we use the max value for the length of a non-fiction title <code class="docutils literal notranslate"><span class="pre">469</span></code> most titles will be much shorter than this, so our function will ‘abstain’ from applying a label, and we would only label a very small number of examples from our data. However, we also won’t have many (or any) wrongly-labeled examples since the max value for fiction here is <code class="docutils literal notranslate"><span class="pre">288</span></code>. We need to balance these two aims of coverage and precision. Since we are writing more than one labeling function we probably want to tend towards writing more precise labeling functions rather than aiming for high coverage if this is likely to introduce wrongly labeled examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As we saw in previous chapters/notebooks we have to be a bit careful in generalizing between what we see in our training and validation data since there may be some distribution drift between our training data (which wasn’t a completely randomized sample) and the full data that we want to label. In the error analysis notebook we saw that the performance of our model was worse than it was on validation data. We should keep this in mind when writing a labeling function, since we want our labeling function to work well on new data which doesn’t have labels, not just on the data for which we already have labels.</p>
</div>
<p>We’ll use the value of the maximum title length for a fiction book as our threshold. This will <em>hopefully</em> give us fairly decent coverage without too many mistakes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">lf_is_long_title</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">NON_FICTION</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">text_len</span> <span class="o">&gt;</span> <span class="mf">211.0</span> <span class="k">else</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>We do the same as earlier, including our new labeling function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">lf_contains_novel</span><span class="p">,</span> <span class="n">lf_is_long_title</span><span class="p">]</span>

<span class="n">applier</span> <span class="o">=</span> <span class="n">PandasLFApplier</span><span class="p">(</span><span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span>
<span class="n">L_train</span> <span class="o">=</span> <span class="n">applier</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 3262/3262 [00:00&lt;00:00, 28729.01it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>j</th>
      <th>Polarity</th>
      <th>Coverage</th>
      <th>Overlaps</th>
      <th>Conflicts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lf_contains_novel</th>
      <td>0</td>
      <td>[0]</td>
      <td>0.058553</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>lf_is_long_title</th>
      <td>1</td>
      <td>[1]</td>
      <td>0.023299</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see our coverage is still fairly low but at the moment we don’t have any conflicts. We can keep tweaking our length threshold but for now we’ll try a different approach to our labeling function.</p>
</div>
<div class="section" id="add-keywords">
<h3>Add Keywords<a class="headerlink" href="#add-keywords" title="Permalink to this headline">¶</a></h3>
<p>We already have a labeling function that uses the keyword ‘novel’ to identify likely fiction books. Since we often want to use keywords the Snorkel tutorial suggests a way we can do this more easily using <a class="reference external" href="https://www.snorkel.org/use-cases/01-spam-tutorial#a-keyword-lfs">keyword lookups</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.labeling</span> <span class="kn">import</span> <span class="n">LabelingFunction</span>


<span class="k">def</span> <span class="nf">keyword_lookup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keywords</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">Title</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">label</span>
    <span class="k">return</span> <span class="n">ABSTAIN</span>


<span class="k">def</span> <span class="nf">make_keyword_lf</span><span class="p">(</span><span class="n">keywords</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">FICTION</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">LabelingFunction</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;keyword_</span><span class="si">{</span><span class="n">keywords</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">f</span><span class="o">=</span><span class="n">keyword_lookup</span><span class="p">,</span>
        <span class="n">resources</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="n">keywords</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">),</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can try two new keyword labels using this more concise approach:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">keyword_tale</span> <span class="o">=</span> <span class="n">make_keyword_lf</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;tale&quot;</span><span class="p">])</span>
<span class="n">keyword_poem</span> <span class="o">=</span> <span class="n">make_keyword_lf</span><span class="p">(</span><span class="n">keywords</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;poem&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="leveraging-other-models">
<h2>Leveraging Other Models<a class="headerlink" href="#leveraging-other-models" title="Permalink to this headline">¶</a></h2>
<p>So far we have leveraged some domain knowledge/exploration and our existing labeled data to create our labeling functions. However, we could also utilise other resources to help us label our data. Since we’re working with text we should be able to benefit from some existing NLP models to label our data. Snorkel supports this in a few different ways.</p>
<p>spaCy is a popular nlp library which supports a range of different models and nlp tasks. Here we’re particuarly interested in some of the named entity models supported by spaCy.</p>
<p>To work with this library we can use Snorkel’s <code class="docutils literal notranslate"><span class="pre">SpacyPreProcessor</span></code>. <code class="docutils literal notranslate"><span class="pre">Preprocessors</span></code> are used in Snorkel to do some preprocessing (hence the name) which is required for our labeling functions. These can be particularly useful if the processing takes some time and might be reused across differnet labelling functions. Let’s take a look at an example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.preprocess.nlp</span> <span class="kn">import</span> <span class="n">SpacyPreprocessor</span>

<span class="c1"># The SpacyPreprocessor parses the text in text_field and</span>
<span class="c1"># stores the new enriched representation in doc_field</span>
<span class="n">spacy</span> <span class="o">=</span> <span class="n">SpacyPreprocessor</span><span class="p">(</span><span class="n">text_field</span><span class="o">=</span><span class="s2">&quot;Title&quot;</span><span class="p">,</span> <span class="n">doc_field</span><span class="o">=</span><span class="s2">&quot;doc&quot;</span><span class="p">,</span> <span class="n">memoize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Above we create a <code class="docutils literal notranslate"><span class="pre">SpacyPreprocessor</span></code> which will use our title field and create a new <code class="docutils literal notranslate"><span class="pre">doc</span></code> field. This <code class="docutils literal notranslate"><span class="pre">doc</span></code> refers to the Spacy <a class="reference external" href="https://spacy.io/api/doc"><code class="docutils literal notranslate"><span class="pre">doc</span></code></a> container. This can be reused for multiple different labeling functions. We pass in <code class="docutils literal notranslate"><span class="pre">memoize=True</span></code> to cache our results. This means we won’t have to wait for the preprocessing to be done multiple times for different labeling functions which reuse the <code class="docutils literal notranslate"><span class="pre">doc</span></code> container.</p>
<div class="section" id="using-named-entities-for-labeling-functions">
<h3>Using named entities for labeling functions.<a class="headerlink" href="#using-named-entities-for-labeling-functions" title="Permalink to this headline">¶</a></h3>
<p>spaCy has support for named entity recognition. Since these models are already created and can be used directly by us it might be worth seeing if named entities are of any benefit for our particular task.</p>
<p>We can again draw from our domain knowledge, intution or guesses (depending on how confident we are) and say that it’s likely that we will see more named entities of the <code class="docutils literal notranslate"><span class="pre">ORG</span></code> type in non-fiction titles since these often will be about organizations. We can combine this with a slightly softer threshold for length to label titles as being likely non-fiction.</p>
<p>To create this function we replicate closely what we did before except that we pass in our <code class="docutils literal notranslate"><span class="pre">SpacyPreProcessor</span></code> instance to let Snorkel know that this preprocesser is a requirement of this labeling function. Under the hood this will mean that if the preprocessor hasn’t been run already this will triger the preprocessing. If we reuse this for another funciton the preprocessing will already have been cached.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="p">[</span><span class="n">spacy</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">has_many_org</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">label_</span> <span class="o">==</span> <span class="s2">&quot;ORG&quot;</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">NON_FICTION</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>We might also guess that there will be more location entities in non-fiction titles</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="p">[</span><span class="n">spacy</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">has_many_loc</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">label_</span> <span class="o">==</span> <span class="s2">&quot;LOC&quot;</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">NON_FICTION</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>Similarly we might also assume that there will be more <code class="docutils literal notranslate"><span class="pre">GPE</span></code> entities for non-fiction</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="p">[</span><span class="n">spacy</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">has_many_gpe</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">label_</span> <span class="o">==</span> <span class="s2">&quot;GPE&quot;</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">NON_FICTION</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>and law entities…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="p">[</span><span class="n">spacy</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">has_law</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">label_</span> <span class="o">==</span> <span class="s2">&quot;LAW&quot;</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">NON_FICTION</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>and if it’s long and has a date it might be a non-fiction title?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="p">[</span><span class="n">spacy</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">is_long_and_has_date</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">label_</span> <span class="o">==</span> <span class="s2">&quot;DATE&quot;</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">NON_FICTION</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>or it is long and has a <code class="docutils literal notranslate"><span class="pre">FAC</span></code> entitity</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">(</span><span class="n">pre</span><span class="o">=</span><span class="p">[</span><span class="n">spacy</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">is_long_and_has_fac</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">50</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">label_</span> <span class="o">==</span> <span class="s2">&quot;FAC&quot;</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">NON_FICTION</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>We now have a bunch of labeling functions we’ll create a new list containing these and see how they do.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lfs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">lf_contains_novel</span><span class="p">,</span>
    <span class="n">lf_is_long_title</span><span class="p">,</span>
    <span class="n">keyword_tale</span><span class="p">,</span>
    <span class="n">keyword_poem</span><span class="p">,</span>
    <span class="n">has_many_org</span><span class="p">,</span>
    <span class="n">has_many_loc</span><span class="p">,</span>
    <span class="n">has_many_gpe</span><span class="p">,</span>
    <span class="n">has_law</span><span class="p">,</span>
    <span class="n">is_long_and_has_date</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">applier</span> <span class="o">=</span> <span class="n">PandasLFApplier</span><span class="p">(</span><span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span>
<span class="n">L_train</span> <span class="o">=</span> <span class="n">applier</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 3262/3262 [00:34&lt;00:00, 93.42it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>j</th>
      <th>Polarity</th>
      <th>Coverage</th>
      <th>Overlaps</th>
      <th>Conflicts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lf_contains_novel</th>
      <td>0</td>
      <td>[0]</td>
      <td>0.058553</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>lf_is_long_title</th>
      <td>1</td>
      <td>[1]</td>
      <td>0.023299</td>
      <td>0.011036</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>keyword_tale</th>
      <td>2</td>
      <td>[0]</td>
      <td>0.043532</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>keyword_poem</th>
      <td>3</td>
      <td>[0]</td>
      <td>0.042918</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>has_many_org</th>
      <td>4</td>
      <td>[1]</td>
      <td>0.011956</td>
      <td>0.011956</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>has_many_loc</th>
      <td>5</td>
      <td>[1]</td>
      <td>0.011036</td>
      <td>0.011036</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>has_many_gpe</th>
      <td>6</td>
      <td>[1]</td>
      <td>0.011036</td>
      <td>0.011036</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>has_law</th>
      <td>7</td>
      <td>[1]</td>
      <td>0.004905</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>is_long_and_has_date</th>
      <td>8</td>
      <td>[1]</td>
      <td>0.003372</td>
      <td>0.003372</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Again our coverage is quite low but we also don’t have too many conflicts. We can check the performance of these functions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_empirical_accuracies</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.        , 0.94736842, 0.97183099, 1.        , 0.92307692,
       0.91666667, 0.91666667, 1.        , 1.        ])
</pre></div>
</div>
</div>
</div>
<p>These are all doing pretty good so we might be okay with lower coverage for now. We also have a resource available to us which should boost our coverage a fair bit: our previously trained model.</p>
</div>
</div>
<div class="section" id="using-our-previous-model">
<h2>Using our previous model<a class="headerlink" href="#using-our-previous-model" title="Permalink to this headline">¶</a></h2>
<p>In a previously notebook we trained a model which didn’t perform terribly. Although we wanted to improve the performance, hence this notebook, it wasn’t so disastrous as to be unusable, particularly with the insights we got from the error analysis notebook that if we raise the threshold of confidence for which we accept our models predictions our performance increases quite a bit. We may therefore want to try and incorporate this model as another way of labeling more data.</p>
<p>There are various ways in which we can do this, we’ll look at one approach below.</p>
<p>We’ll start by importing fastai so we can load our previously trained model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<p>If you don’t have a model saved from notebook you can download one by uncommenting the below cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !wget -O 20210928-model.pkl  https://zenodo.org/record/5245175/files/20210928-model.pkl?download=1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2021-11-11 14:12:20--  https://zenodo.org/record/5245175/files/20210928-model.pkl?download=1
Resolving zenodo.org (zenodo.org)... 137.138.76.77
Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 158529715 (151M) [application/octet-stream]
Saving to: ‘20210928-model.pkl’

20210928-model.pkl  100%[===================&gt;] 151.19M  11.1MB/s    in 16s     

2021-11-11 14:12:38 (9.54 MB/s) - ‘20210928-model.pkl’ saved [158529715/158529715]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="s2">&quot;20210928-model.pkl&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can quickly check our vocab</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Fiction&#39;, &#39;Non-fiction&#39;]
</pre></div>
</div>
</div>
</div>
<p>One way of using this model would be to create a preprocessor that will be used by Snorkel. This will do the setup required to use this model (as we saw with the spaCy example). We can do this by using the <code class="docutils literal notranslate"><span class="pre">preprocessor</span></code> decorator. Our function then calls whatever we need to happen. In this case we store the predicted label and probability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from snorkel.preprocess import preprocessor</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @preprocessor(memoize=True)</span>
<span class="c1"># def fastai_pred(x):</span>
<span class="c1">#     with learn.no_bar():</span>
<span class="c1">#         *_, probs = learn.predict(x.title)</span>
<span class="c1">#     x.fiction_prob = probs[0]</span>
<span class="c1">#     x.non_fiction_prob = probs[1]</span>
<span class="c1">#     return x</span>
</pre></div>
</div>
</div>
</div>
<p>In this example we don’t want to use this since we then don’t benefit from doing our inference in batches. Instead we’ll just create some new columns to store our fastai models labels and confidence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_dl</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">test_dl</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Title</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">dl</span><span class="o">=</span><span class="n">test_dl</span><span class="p">)</span>
<span class="n">fiction_prob</span><span class="p">,</span> <span class="n">non_fiction_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fiction_prob</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.9999399 ],
       [0.9999399 ],
       [0.9999399 ],
       ...,
       [0.04363291],
       [0.04363291],
       [0.02832149]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;fiction_prob&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fiction_prob</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;non_fiction_prob&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">non_fiction_prob</span>
</pre></div>
</div>
</div>
</div>
<p>We now have some new columns containing the probabilities for our labels from our previously created model.</p>
<p>We saw in the previous <a class="reference internal" href="02_error_analysis.html"><span class="doc std std-doc">Assessing Where our Model is Going Wrong</span></a> section that by only using predictions where our model was confident, we could get better results i.e. we only accept suggestions from our model where it is very confident. For example, we could accept a prediction only if it is above 95% confidence.</p>
<p>We’ll use this in our labelling function to set a threshold at which we accept the previous models predictions. If the model is unsure we don’t use it’s prediction. This will mean less of our data ends up labelled because some predictions aren’t used. However, we will hopefully get <em>better</em> predictions because we only use those where our model is confident.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">fastai_fiction_prob_v_high</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">FICTION</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">fiction_prob</span> <span class="o">&gt;</span> <span class="mf">0.97</span> <span class="k">else</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@labeling_function</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">fastai_non_fiction_prob_v_high</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">NON_FICTION</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">non_fiction_prob</span> <span class="o">&gt;</span> <span class="mf">0.97</span> <span class="k">else</span> <span class="n">ABSTAIN</span>
</pre></div>
</div>
</div>
</div>
<p>Again we add this to our existing labeling function list and apply it to our data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lfs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">fastai_fiction_prob_v_high</span><span class="p">,</span> <span class="n">fastai_non_fiction_prob_v_high</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lfs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[LabelingFunction lf_contains_novel, Preprocessors: [],
 LabelingFunction lf_is_long_title, Preprocessors: [],
 LabelingFunction keyword_tale, Preprocessors: [],
 LabelingFunction keyword_poem, Preprocessors: [],
 LabelingFunction has_many_org, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],
 LabelingFunction has_many_loc, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],
 LabelingFunction has_many_gpe, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],
 LabelingFunction has_law, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],
 LabelingFunction is_long_and_has_date, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []],
 LabelingFunction fastai_fiction_prob_v_high, Preprocessors: [],
 LabelingFunction fastai_non_fiction_prob_v_high, Preprocessors: []]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">applier</span> <span class="o">=</span> <span class="n">PandasLFApplier</span><span class="p">(</span><span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span>
<span class="n">L_train</span> <span class="o">=</span> <span class="n">applier</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 3262/3262 [00:34&lt;00:00, 95.06it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>j</th>
      <th>Polarity</th>
      <th>Coverage</th>
      <th>Overlaps</th>
      <th>Conflicts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lf_contains_novel</th>
      <td>0</td>
      <td>[0]</td>
      <td>0.058553</td>
      <td>0.056101</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>lf_is_long_title</th>
      <td>1</td>
      <td>[1]</td>
      <td>0.023299</td>
      <td>0.019926</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>keyword_tale</th>
      <td>2</td>
      <td>[0]</td>
      <td>0.043532</td>
      <td>0.034028</td>
      <td>0.000613</td>
    </tr>
    <tr>
      <th>keyword_poem</th>
      <td>3</td>
      <td>[0]</td>
      <td>0.042918</td>
      <td>0.035561</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>has_many_org</th>
      <td>4</td>
      <td>[1]</td>
      <td>0.011956</td>
      <td>0.011956</td>
      <td>0.000920</td>
    </tr>
    <tr>
      <th>has_many_loc</th>
      <td>5</td>
      <td>[1]</td>
      <td>0.011036</td>
      <td>0.011036</td>
      <td>0.000920</td>
    </tr>
    <tr>
      <th>has_many_gpe</th>
      <td>6</td>
      <td>[1]</td>
      <td>0.011036</td>
      <td>0.011036</td>
      <td>0.000920</td>
    </tr>
    <tr>
      <th>has_law</th>
      <td>7</td>
      <td>[1]</td>
      <td>0.004905</td>
      <td>0.002759</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>is_long_and_has_date</th>
      <td>8</td>
      <td>[1]</td>
      <td>0.003372</td>
      <td>0.003372</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>fastai_fiction_prob_v_high</th>
      <td>9</td>
      <td>[0]</td>
      <td>0.223483</td>
      <td>0.125996</td>
      <td>0.000920</td>
    </tr>
    <tr>
      <th>fastai_non_fiction_prob_v_high</th>
      <td>10</td>
      <td>[1]</td>
      <td>0.338749</td>
      <td>0.021153</td>
      <td>0.000613</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see that the labelling function which uses our model outputs has a much higher coverage of our data. This should be very helpful in labelling more examples but we want to check that these are correct.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_empirical_accuracies</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.        , 0.94736842, 0.97183099, 1.        , 0.92307692,
       0.91666667, 0.91666667, 1.        , 1.        , 0.99314129,
       0.99909502])
</pre></div>
</div>
</div>
</div>
<p>We can see that our labels all perform pretty well i.e. above 90%. We are also getting much better coverage now that we leverage our existing model.</p>
</div>
<div class="section" id="creating-more-training-data">
<h2>Creating more training data<a class="headerlink" href="#creating-more-training-data" title="Permalink to this headline">¶</a></h2>
<p>So far we have been using the validation data to develop some potential labeling functions. Now we are fairly satisfied with them let’s apply to the full data. We’ll quickly look at this process on our current data and then we’ll move to the full metadata json file that we use for creating more training data.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">LabelModel</span></code> to fit a model which will be able to take as input all of the predictions from our labelling functions and fit a model which will predict the probability for a label. This model is able to deal with some conflicts between labeling functions and will do much better in most cases than a naive majority vote model i.e. one which just accepts the most often predicted label. The details of this model are beyond the scope of this notebook but if you are interested <em>Data Programming: Creating Large Training Sets, Quickly</em> offers a fuller overview of the details of this method<span id="id1">[<a class="reference internal" href="references.html#id21">8</a>]</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.labeling.model</span> <span class="kn">import</span> <span class="n">LabelModel</span>

<span class="n">label_model</span> <span class="o">=</span> <span class="n">LabelModel</span><span class="p">(</span><span class="n">cardinality</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">label_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">L_train</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">log_freq</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Above we fit our <code class="docutils literal notranslate"><span class="pre">LabelModel</span></code> for 500 epochs. Since we are working with the training set still we can get the score for this model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span>
    <span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span>
    <span class="n">Y</span><span class="o">=</span><span class="n">ground_truth</span><span class="p">,</span>
    <span class="n">tie_break_policy</span><span class="o">=</span><span class="s2">&quot;abstain&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:root:Metrics calculated over data points with non-abstain labels only
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;f1&#39;: 0.994250331711632,
 &#39;precision&#39;: 0.9964539007092199,
 &#39;recall&#39;: 0.9920564872021183}
</pre></div>
</div>
</div>
</div>
<p>This is looking pretty good and hopefully this performance will be similar for our full data. We’ll now load a dataframe that includes all of the BL books metadata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_full</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://bl.iro.bl.uk/downloads/e1be1324-8b1a-4712-96a7-783ac209ddef?locale=en&quot;</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We create a new column <code class="docutils literal notranslate"><span class="pre">text_len</span></code> since we need this for some of our labeling functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_full</span><span class="p">[</span><span class="s2">&quot;text_len&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_full</span><span class="o">.</span><span class="n">Title</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We also get our fastai model’s predictions into new columns. This obviously takes some time since we’re now doing inference on a fairly large dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_dl</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">test_dl</span><span class="p">(</span><span class="n">df_full</span><span class="o">.</span><span class="n">Title</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">dl</span><span class="o">=</span><span class="n">test_dl</span><span class="p">)</span>
<span class="n">fiction_prob</span><span class="p">,</span> <span class="n">non_fiction_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">df_full</span><span class="p">[</span><span class="s2">&quot;fiction_prob&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fiction_prob</span>
<span class="n">df_full</span><span class="p">[</span><span class="s2">&quot;non_fiction_prob&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">non_fiction_prob</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div></div>
</div>
<p>Now we have all the same columns in place as we had previously we can now apply our labelling functions to all of our data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">applier</span> <span class="o">=</span> <span class="n">PandasLFApplier</span><span class="p">(</span><span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span>
<span class="n">L_train</span> <span class="o">=</span> <span class="n">applier</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df_full</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 52695/52695 [09:27&lt;00:00, 92.85it/s] 
</pre></div>
</div>
</div>
</div>
<p>We can check what the coverage, overlaps and conflicts look like</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LFAnalysis</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">lfs</span><span class="o">=</span><span class="n">lfs</span><span class="p">)</span><span class="o">.</span><span class="n">lf_summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>j</th>
      <th>Polarity</th>
      <th>Coverage</th>
      <th>Overlaps</th>
      <th>Conflicts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lf_contains_novel</th>
      <td>0</td>
      <td>[0]</td>
      <td>0.066875</td>
      <td>0.057178</td>
      <td>0.000285</td>
    </tr>
    <tr>
      <th>lf_is_long_title</th>
      <td>1</td>
      <td>[1]</td>
      <td>0.047367</td>
      <td>0.032413</td>
      <td>0.003036</td>
    </tr>
    <tr>
      <th>keyword_tale</th>
      <td>2</td>
      <td>[0]</td>
      <td>0.036702</td>
      <td>0.022165</td>
      <td>0.001006</td>
    </tr>
    <tr>
      <th>keyword_poem</th>
      <td>3</td>
      <td>[0]</td>
      <td>0.089952</td>
      <td>0.049018</td>
      <td>0.002619</td>
    </tr>
    <tr>
      <th>has_many_org</th>
      <td>4</td>
      <td>[1]</td>
      <td>0.021520</td>
      <td>0.021520</td>
      <td>0.001974</td>
    </tr>
    <tr>
      <th>has_many_loc</th>
      <td>5</td>
      <td>[1]</td>
      <td>0.021008</td>
      <td>0.021008</td>
      <td>0.001917</td>
    </tr>
    <tr>
      <th>has_many_gpe</th>
      <td>6</td>
      <td>[1]</td>
      <td>0.021008</td>
      <td>0.021008</td>
      <td>0.001917</td>
    </tr>
    <tr>
      <th>has_law</th>
      <td>7</td>
      <td>[1]</td>
      <td>0.004232</td>
      <td>0.002106</td>
      <td>0.000531</td>
    </tr>
    <tr>
      <th>is_long_and_has_date</th>
      <td>8</td>
      <td>[1]</td>
      <td>0.007762</td>
      <td>0.007762</td>
      <td>0.000380</td>
    </tr>
    <tr>
      <th>fastai_fiction_prob_v_high</th>
      <td>9</td>
      <td>[0]</td>
      <td>0.213834</td>
      <td>0.122858</td>
      <td>0.000626</td>
    </tr>
    <tr>
      <th>fastai_non_fiction_prob_v_high</th>
      <td>10</td>
      <td>[1]</td>
      <td>0.192599</td>
      <td>0.019015</td>
      <td>0.000683</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The coverage is lower than we had previously. This makes sense since we previously used the same data for developing our labeling functions as we used for training our model. It’s not suprising our model is more confident about these. If we were being more dilligent we might have held back a different dataset for developing our labelling functions but since we’re being a bit pragmatic (lazy) here we won’t worry too much about this. We can again fit our model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_model</span> <span class="o">=</span> <span class="n">LabelModel</span><span class="p">(</span><span class="n">cardinality</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">label_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">L_train</span><span class="o">=</span><span class="n">L_train</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">log_freq</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We now use this model to predict the probabilites from our labelling function outputs</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probs_train</span> <span class="o">=</span> <span class="n">label_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">L_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We currently have predictions for some of our data but not all of it. Since we want only the labelled exampled we use a function from Snorkel to filter out data which our labeling functions didn’t annotate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.labeling</span> <span class="kn">import</span> <span class="n">filter_unlabeled_dataframe</span>

<span class="n">df_train_filtered</span><span class="p">,</span> <span class="n">probs_train_filtered</span> <span class="o">=</span> <span class="n">filter_unlabeled_dataframe</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">df_full</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">probs_train</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="n">L_train</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We now have the predicted probabilty for each label. We could work with these probabilities but to keep things simple we’ll make these hard predictions i.e. fiction or non-fiction rather than 0.87% fiction. Again Snorkel provides a handy function for doing this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">snorkel.utils</span> <span class="kn">import</span> <span class="n">probs_to_preds</span>

<span class="n">preds_train_filtered</span> <span class="o">=</span> <span class="n">probs_to_preds</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">probs_train_filtered</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see how much data we have now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">preds_train_filtered</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>26566
</pre></div>
</div>
</div>
</div>
<p>As a reminder we previosuly had <code class="docutils literal notranslate"><span class="pre">3262</span></code> labeled examples. We can see that we’ve now gained a lot more examples for relateively little work (especially if we compare how much time it would take to annotate these by hand).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">26566</span> <span class="o">/</span> <span class="mi">3262</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8.144083384426732
</pre></div>
</div>
</div>
</div>
<p>We’ll store out new labels in a label column</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train_filtered</span><span class="p">[</span><span class="s2">&quot;snorkel_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds_train_filtered</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  &quot;&quot;&quot;Entry point for launching an IPython kernel.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train_filtered</span><span class="p">[</span><span class="s2">&quot;snorkel_label&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0        0
1        0
2        0
3        0
8        0
        ..
52682    0
52689    0
52692    0
52693    0
52694    0
Name: snorkel_label, Length: 26566, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="creating-our-new-training-data">
<h2>Creating our new training data<a class="headerlink" href="#creating-our-new-training-data" title="Permalink to this headline">¶</a></h2>
<p>As a reminder of what we’ve done:</p>
<ul class="simple">
<li><p>we had training data/annotations collected via a zooniverse crowdsourcing task with <code class="docutils literal notranslate"><span class="pre">2909</span></code> labeled examples in our validation set</p></li>
<li><p>we had previously used this to train a model that did fairly well</p></li>
<li><p>we used our existing training data to generate labeling functions, these leveraged:</p>
<ul>
<li><p>our intuitions about our data</p></li>
<li><p>SpaCy models</p></li>
<li><p>our previous model</p></li>
</ul>
</li>
<li><p>we applied these labeling functions to the Microsoft Digitised Books file. Once we excluded examples which weren’t labeled by our labeling functions we had <code class="docutils literal notranslate"><span class="pre">34542</span></code> labeled examples we could work with.</p></li>
</ul>
<p>We now want to get all of this data into a format we can use to train new models with. There are a few things we need to do for this.</p>
<div class="section" id="map-to-our-original-labels">
<h3>Map to our original labels<a class="headerlink" href="#map-to-our-original-labels" title="Permalink to this headline">¶</a></h3>
<p>We’ll map these back to our original fiction and non-fiction labels. This isn’t super important but might be more explicit then <code class="docutils literal notranslate"><span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">0</span></code> for our labels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train_filtered</span><span class="p">[</span><span class="s2">&quot;snorkel_genre&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_train_filtered</span><span class="p">[</span><span class="s2">&quot;snorkel_label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;Fiction&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;Non-fiction&quot;</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train_filtered</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;BL record ID&#39;, &#39;Type of resource&#39;, &#39;Name&#39;,
       &#39;Dates associated with name&#39;, &#39;Type of name&#39;, &#39;Role&#39;, &#39;All names&#39;,
       &#39;Title&#39;, &#39;Variant titles&#39;, &#39;Series title&#39;, &#39;Number within series&#39;,
       &#39;Country of publication&#39;, &#39;Place of publication&#39;, &#39;Publisher&#39;,
       &#39;Date of publication&#39;, &#39;Edition&#39;, &#39;Physical description&#39;,
       &#39;Dewey classification&#39;, &#39;BL shelfmark&#39;, &#39;Topics&#39;, &#39;Genre&#39;, &#39;Languages&#39;,
       &#39;Notes&#39;, &#39;BL record ID for physical resource&#39;, &#39;text_len&#39;,
       &#39;fiction_prob&#39;, &#39;non_fiction_prob&#39;, &#39;snorkel_label&#39;, &#39;snorkel_genre&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="selecting-required-columns">
<h3>Selecting required columns<a class="headerlink" href="#selecting-required-columns" title="Permalink to this headline">¶</a></h3>
<p>Since we have only been using the title and the label (fiction or non-fiction) to train our models we will just keep these.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;annotator_genre&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0           Fiction
1           Fiction
2           Fiction
3           Fiction
4           Fiction
           ...     
3257    Non-fiction
3258    Non-fiction
3259    Non-fiction
3260    Non-fiction
3261    Non-fiction
Name: annotator_genre, Length: 3262, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;snorkel_genre&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;annotator_genre&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_snorkel_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">df_train_filtered</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_snorkel_train</span><span class="p">[</span><span class="s2">&quot;snorkel_genre&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fiction        15840
Non-fiction    13988
Name: snorkel_genre, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="prioritising-human-annotations">
<h3>Prioritising human annotations<a class="headerlink" href="#prioritising-human-annotations" title="Permalink to this headline">¶</a></h3>
<p>When we applied our labeling functions across the full Microsoft Digitised Books metadata file we didn’t do anything to exclude titles where a human annotator had already provided a label as part of the Zooniverse annotation task. Since we joined the full metadata and the human annotations together we will now have some duplicates. We almost definitely want to prioritise the human annotations over our label function labels. We could use Pandas drop_duplicates and keep the first example (the human annotated one) to deal with this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_snorkel_train</span><span class="o">.</span><span class="n">duplicated</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s2">&quot;Title&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0        False
1         True
2         True
3         True
4         True
         ...  
52682    False
52689    False
52692    False
52693    False
52694    False
Length: 29828, dtype: bool
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_snorkel_train</span> <span class="o">=</span> <span class="n">df_snorkel_train</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s2">&quot;Title&quot;</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="s2">&quot;first&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_snorkel_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BL record ID</th>
      <th>Type of resource</th>
      <th>Name</th>
      <th>Dates associated with name</th>
      <th>Type of name</th>
      <th>Role</th>
      <th>All names</th>
      <th>Title</th>
      <th>Variant titles</th>
      <th>Series title</th>
      <th>Number within series</th>
      <th>Country of publication</th>
      <th>Place of publication</th>
      <th>Publisher</th>
      <th>Date of publication</th>
      <th>Edition</th>
      <th>Physical description</th>
      <th>Dewey classification</th>
      <th>BL shelfmark</th>
      <th>Topics</th>
      <th>Genre</th>
      <th>Languages</th>
      <th>Notes</th>
      <th>BL record ID for physical resource</th>
      <th>classification_id</th>
      <th>user_id</th>
      <th>created_at</th>
      <th>subject_ids</th>
      <th>annotator_date_pub</th>
      <th>annotator_normalised_date_pub</th>
      <th>annotator_edition_statement</th>
      <th>annotator_genre</th>
      <th>annotator_FAST_genre_terms</th>
      <th>annotator_FAST_subject_terms</th>
      <th>annotator_comments</th>
      <th>annotator_main_language</th>
      <th>annotator_other_languages_summaries</th>
      <th>annotator_summaries_language</th>
      <th>annotator_translation</th>
      <th>annotator_original_language</th>
      <th>annotator_publisher</th>
      <th>annotator_place_pub</th>
      <th>annotator_country</th>
      <th>annotator_title</th>
      <th>Link to digitised book</th>
      <th>annotated</th>
      <th>is_valid</th>
      <th>text_len</th>
      <th>fiction_prob</th>
      <th>non_fiction_prob</th>
      <th>snorkel_genre</th>
      <th>snorkel_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>014616539</td>
      <td>Monograph</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Hazlitt, William Carew, 1834-1913 [person]</td>
      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>
      <td>Single Works</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Scotland</td>
      <td>Edinburgh</td>
      <td>Ballantyne, Hanson</td>
      <td>1877</td>
      <td>NaN</td>
      <td>20 pages (4°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 11651.h.6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000206670</td>
      <td>263940444.0</td>
      <td>3.0</td>
      <td>2020-07-27 07:35:13 UTC</td>
      <td>44330917.0</td>
      <td>1877</td>
      <td>1877</td>
      <td>NONE</td>
      <td>Fiction</td>
      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>
      <td>NONE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>&lt;NA&gt;</td>
      <td>No</td>
      <td>NaN</td>
      <td>Ballantyne Hanson &amp; Co.</td>
      <td>Edinburgh</td>
      <td>stk</td>
      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>
      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F718</td>
      <td>True</td>
      <td>False</td>
      <td>100</td>
      <td>0.999940</td>
      <td>0.000060</td>
      <td>Fiction</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>014616561</td>
      <td>Monograph</td>
      <td>Bingham, Ashton, Mrs</td>
      <td>NaN</td>
      <td>person</td>
      <td>NaN</td>
      <td>Bingham, Ashton, Mrs [person]</td>
      <td>The Autumn Leaf Poems</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Scotland</td>
      <td>Edinburgh</td>
      <td>Colston</td>
      <td>1891</td>
      <td>NaN</td>
      <td>vi, 104 pages (8°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 011649.e.105</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000353271</td>
      <td>268728281.0</td>
      <td>3.0</td>
      <td>2020-08-18 07:02:17 UTC</td>
      <td>44331070.0</td>
      <td>1891</td>
      <td>1891</td>
      <td>NONE</td>
      <td>Fiction</td>
      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>
      <td>NONE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>&lt;NA&gt;</td>
      <td>No</td>
      <td>NaN</td>
      <td>Colston &amp; Company</td>
      <td>Edinburgh</td>
      <td>stk</td>
      <td>The Autumn Leaf Poems</td>
      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F04C</td>
      <td>True</td>
      <td>False</td>
      <td>21</td>
      <td>0.999486</td>
      <td>0.000514</td>
      <td>Fiction</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>10</th>
      <td>014616607</td>
      <td>Monograph</td>
      <td>Cartwright, William</td>
      <td>NaN</td>
      <td>person</td>
      <td>writer</td>
      <td>Cartwright, William, writer [person]</td>
      <td>The Battle of Waterloo, a poem</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>London</td>
      <td>Longman</td>
      <td>1827</td>
      <td>NaN</td>
      <td>vii, 71 pages (8°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 992.i.26</td>
      <td>Waterloo, Battle of (Belgium : 1815)</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000621918</td>
      <td>263935396.0</td>
      <td>3.0</td>
      <td>2020-07-27 06:39:57 UTC</td>
      <td>44331748.0</td>
      <td>1827</td>
      <td>1827</td>
      <td>NONE</td>
      <td>Fiction</td>
      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>
      <td>647 7 $aBattle of Waterloo$c(Waterloo, Belgium :$d1815)$2fast$0(OCoLC)fst01172689</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>&lt;NA&gt;</td>
      <td>No</td>
      <td>NaN</td>
      <td>Longman, Rees, Orme, Brown &amp; Green\nBurlton\nMerricks</td>
      <td>London\nLeominster\nHereford</td>
      <td>enk</td>
      <td>The Battle of Waterloo, a poem</td>
      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002ED4C</td>
      <td>True</td>
      <td>False</td>
      <td>30</td>
      <td>0.991599</td>
      <td>0.008401</td>
      <td>Fiction</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>15</th>
      <td>014616686</td>
      <td>Monograph</td>
      <td>Earle, John Charles</td>
      <td>NaN</td>
      <td>person</td>
      <td>NaN</td>
      <td>Earle, John Charles [person]</td>
      <td>Maximilian, and other poems, etc</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>London</td>
      <td>NaN</td>
      <td>1868</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 11648.i.8</td>
      <td>NaN</td>
      <td>Poetry or verse</td>
      <td>English</td>
      <td>NaN</td>
      <td>001025896</td>
      <td>265570129.0</td>
      <td>3.0</td>
      <td>2020-08-03 07:25:30 UTC</td>
      <td>44331725.0</td>
      <td>1868</td>
      <td>1868</td>
      <td>NONE</td>
      <td>Fiction</td>
      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>
      <td>NONE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>&lt;NA&gt;</td>
      <td>No</td>
      <td>NaN</td>
      <td>Burns, Oates, &amp; Co.</td>
      <td>London</td>
      <td>enk</td>
      <td>Maximilian, and other poems, etc</td>
      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F2AA</td>
      <td>True</td>
      <td>False</td>
      <td>32</td>
      <td>0.982546</td>
      <td>0.017454</td>
      <td>Fiction</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>20</th>
      <td>014616696</td>
      <td>Monograph</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Fabellæ mostellariæ: or Devonshire and Wiltshire stories in verse; including specimens of the Devonshire dialect</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>Exeter ; London</td>
      <td>Hamilton, Adams ; Henry S. Eland</td>
      <td>1878</td>
      <td>NaN</td>
      <td>77 pages (8°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 11652.h.19</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>001187981</td>
      <td>269169228.0</td>
      <td>3.0</td>
      <td>2020-08-20 12:32:34 UTC</td>
      <td>44331389.0</td>
      <td>1878</td>
      <td>1878</td>
      <td>NONE</td>
      <td>Fiction</td>
      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>
      <td>NONE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>&lt;NA&gt;</td>
      <td>No</td>
      <td>NaN</td>
      <td>Hamilton, Adams, and Co.\nHenry S. Eland</td>
      <td>London\nExeter</td>
      <td>enk</td>
      <td>Fabellæ mostellariæ: or Devonshire and Wiltshire stories in verse; including specimens of the Devonshire dialect</td>
      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F90A</td>
      <td>True</td>
      <td>False</td>
      <td>112</td>
      <td>0.983944</td>
      <td>0.016056</td>
      <td>Fiction</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>52682</th>
      <td>016289050</td>
      <td>Monograph</td>
      <td>Hastings, Beatrice</td>
      <td>NaN</td>
      <td>person</td>
      <td>NaN</td>
      <td>Hastings, Beatrice [person]</td>
      <td>The maids' comedy. A chivalric romance in thirteen chapters</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>London</td>
      <td>Stephen Swift</td>
      <td>1911</td>
      <td>NaN</td>
      <td>199 pages, 20 cm</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 012618.c.32</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>Anonymous. By Beatrice Hastings</td>
      <td>004111105</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>&lt;NA&gt;</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>59</td>
      <td>0.999444</td>
      <td>0.000556</td>
      <td>Fiction</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>52689</th>
      <td>016289057</td>
      <td>Monograph</td>
      <td>Garstang, Walter, M.A., F.Z.S.</td>
      <td>NaN</td>
      <td>person</td>
      <td>NaN</td>
      <td>Garstang, Walter, M.A., F.Z.S. [person] ; Shepherd, J. A. (James Affleck), 1867-approximately 1931 [person]</td>
      <td>Songs of the Birds ... With illustrations by J.A. Shepherd</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>London</td>
      <td>John Lane</td>
      <td>1922</td>
      <td>NaN</td>
      <td>101 pages, illustrations (8°)</td>
      <td>598.259</td>
      <td>Digital Store 011648.g.133</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>Poems, with and introductory essay</td>
      <td>004158005</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>&lt;NA&gt;</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>58</td>
      <td>0.993942</td>
      <td>0.006058</td>
      <td>Fiction</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>52692</th>
      <td>016289060</td>
      <td>Monograph</td>
      <td>Wellesley, Dorothy</td>
      <td>1889-1956</td>
      <td>person</td>
      <td>NaN</td>
      <td>Wellesley, Dorothy, 1889-1956 [person]</td>
      <td>Early Poems. By M. A [i.e. Dorothy Violet Wellesley, Lady Gerald Wellesley.]</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>London</td>
      <td>Elkin Mathews</td>
      <td>1913</td>
      <td>NaN</td>
      <td>vii, 90 pages (8°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 011649.eee.17</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000000839</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>&lt;NA&gt;</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>76</td>
      <td>0.987218</td>
      <td>0.012782</td>
      <td>Fiction</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>52693</th>
      <td>016289061</td>
      <td>Monograph</td>
      <td>A, T. H. E.</td>
      <td>NaN</td>
      <td>person</td>
      <td>NaN</td>
      <td>A, T. H. E. [person]</td>
      <td>Of Life and Love [Poems.] By T. H. E. A, writer of 'The Message.'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>London</td>
      <td>J. M. Watkins</td>
      <td>1924</td>
      <td>NaN</td>
      <td>89 pages (8°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 011645.e.125</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000001167</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>&lt;NA&gt;</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>65</td>
      <td>0.977032</td>
      <td>0.022968</td>
      <td>Fiction</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>52694</th>
      <td>016289062</td>
      <td>Monograph</td>
      <td>Abbay, Richard</td>
      <td>NaN</td>
      <td>person</td>
      <td>NaN</td>
      <td>Abbay, Richard [person]</td>
      <td>Life, a Mode of Motion; or, He and I, my two selves [A poem.]</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>England</td>
      <td>London</td>
      <td>Jarrold</td>
      <td>1919</td>
      <td>NaN</td>
      <td>volumes, 58 pages (8°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 011649.g.81</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000003140</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>&lt;NA&gt;</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>61</td>
      <td>0.975888</td>
      <td>0.024112</td>
      <td>Fiction</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>25683 rows × 52 columns</p>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="data-leakage">
<h2>Data leakage<a class="headerlink" href="#data-leakage" title="Permalink to this headline">¶</a></h2>
<p>Want to exclude data which is in test set so we drop these examples from our training data. Since we care about titles ‘leaking’ we look up whether any titles in our training data appear in our test data and remove these from the training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;test_errors.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="removing-data-which-is-in-our-test-data">
<h3>Removing data which is in our test data<a class="headerlink" href="#removing-data-which-is-in-our-test-data" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_snorkel_train</span> <span class="o">=</span> <span class="n">df_snorkel_train</span><span class="p">[</span><span class="o">~</span><span class="n">df_snorkel_train</span><span class="o">.</span><span class="n">Title</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">df_test</span><span class="o">.</span><span class="n">title</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df_snorkel_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>25683
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="creating-new-splits">
<h3>Creating new splits<a class="headerlink" href="#creating-new-splits" title="Permalink to this headline">¶</a></h3>
<p>We create some new splits following the same process we used before. We can then use these splits to more accurately compare across models training using this dataset. Since we have kept the test data out of our ‘Snorkel dataset’ we will also continue to use this test data for final model evaluation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupShuffleSplit</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_inds</span><span class="p">,</span> <span class="n">valid_ins</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
    <span class="n">GroupShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
        <span class="n">df_snorkel_train</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">df_snorkel_train</span><span class="p">[</span><span class="s2">&quot;Title&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_valid</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_snorkel_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_inds</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
    <span class="n">df_snorkel_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">valid_ins</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;is_valid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">df_valid</span><span class="p">[</span><span class="s2">&quot;is_valid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_train</span><span class="p">,</span> <span class="n">df_valid</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">snorkel_genre</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fiction        13918
Non-fiction    11765
Name: snorkel_genre, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>We can see we still have a healthy number of examples to train our model on even after dropping titles which appear in our test data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>25683
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="saving-our-new-training-data">
<h2>Saving our new training data<a class="headerlink" href="#saving-our-new-training-data" title="Permalink to this headline">¶</a></h2>
<p>We’ll save our new training data as a csv file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;data/snorkel_train.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BL record ID</th>
      <th>Type of resource</th>
      <th>Name</th>
      <th>Dates associated with name</th>
      <th>Type of name</th>
      <th>Role</th>
      <th>All names</th>
      <th>Title</th>
      <th>Variant titles</th>
      <th>Series title</th>
      <th>Number within series</th>
      <th>Country of publication</th>
      <th>Place of publication</th>
      <th>Publisher</th>
      <th>Date of publication</th>
      <th>Edition</th>
      <th>Physical description</th>
      <th>Dewey classification</th>
      <th>BL shelfmark</th>
      <th>Topics</th>
      <th>Genre</th>
      <th>Languages</th>
      <th>Notes</th>
      <th>BL record ID for physical resource</th>
      <th>classification_id</th>
      <th>user_id</th>
      <th>created_at</th>
      <th>subject_ids</th>
      <th>annotator_date_pub</th>
      <th>annotator_normalised_date_pub</th>
      <th>annotator_edition_statement</th>
      <th>annotator_genre</th>
      <th>annotator_FAST_genre_terms</th>
      <th>annotator_FAST_subject_terms</th>
      <th>annotator_comments</th>
      <th>annotator_main_language</th>
      <th>annotator_other_languages_summaries</th>
      <th>annotator_summaries_language</th>
      <th>annotator_translation</th>
      <th>annotator_original_language</th>
      <th>annotator_publisher</th>
      <th>annotator_place_pub</th>
      <th>annotator_country</th>
      <th>annotator_title</th>
      <th>Link to digitised book</th>
      <th>annotated</th>
      <th>is_valid</th>
      <th>text_len</th>
      <th>fiction_prob</th>
      <th>non_fiction_prob</th>
      <th>snorkel_genre</th>
      <th>snorkel_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>014616539</td>
      <td>Monograph</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Hazlitt, William Carew, 1834-1913 [person]</td>
      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>
      <td>Single Works</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Scotland</td>
      <td>Edinburgh</td>
      <td>Ballantyne, Hanson</td>
      <td>1877</td>
      <td>NaN</td>
      <td>20 pages (4°)</td>
      <td>&lt;NA&gt;</td>
      <td>Digital Store 11651.h.6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>English</td>
      <td>NaN</td>
      <td>000206670</td>
      <td>263940444.0</td>
      <td>3.0</td>
      <td>2020-07-27 07:35:13 UTC</td>
      <td>44330917.0</td>
      <td>1877</td>
      <td>1877</td>
      <td>NONE</td>
      <td>Fiction</td>
      <td>655 7 $aPoetry$2fast$0(OCoLC)fst01423828</td>
      <td>NONE</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>No</td>
      <td>&lt;NA&gt;</td>
      <td>No</td>
      <td>NaN</td>
      <td>Ballantyne Hanson &amp; Co.</td>
      <td>Edinburgh</td>
      <td>stk</td>
      <td>The Baron's Daughter. A ballad by the author of Poetical Recreations [i.e. William C. Hazlitt] . F.P</td>
      <td>http://access.bl.uk/item/viewer/ark:/81055/vdc_00000002F718</td>
      <td>True</td>
      <td>False</td>
      <td>100</td>
      <td>0.99994</td>
      <td>0.00006</td>
      <td>Fiction</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline">¶</a></h2>
<p>We now have a larger training set which includes both our original training data produced through crowdsourcing plus our training data we generated using our labeling functions and the Snorkel library.</p>
<p>Hopefully having more training data will result in being able to improve the models we can generate. In the next sections we’ll look at two approaches we can use for doing this:</p>
<ul class="simple">
<li><p>training the same model as before but with more data</p></li>
<li><p>training a transformer based model with more data</p></li>
</ul>
<p>We will hopefully see some improvements now we have more data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The main things we tried to show in this notebook:</p>
<ul class="simple">
<li><p>we can leverage our domain knowledge to help generate training data using a programmatic data labeling approach</p></li>
<li><p>this approach can leverage existing training data generated by humans</p></li>
<li><p>we can often use existing models to help generate training data even if the task is quite different</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="02_error_analysis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Assessing Where our Model is Going Wrong</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="04_using_our_new_data.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Using our newly expanded data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Daniel van Strien, Giorgia Tolfo, Victoria Morris, Kaspar Beelen<br/>
        
            &copy; Copyright 2021 The Alan Turing Institute, British Library Board, Queen Mary University of London, University of Exeter, University of East Anglia and University of Cambridge..<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>